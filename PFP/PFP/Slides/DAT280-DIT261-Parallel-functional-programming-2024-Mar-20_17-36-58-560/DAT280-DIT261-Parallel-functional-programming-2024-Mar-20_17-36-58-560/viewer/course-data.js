window.COURSE_DATA = {"language":"en-GB","lastDownload":"2024-03-20T18:36:19+01:00","title":"DAT280 / DIT261 Parallel functional programming","modules":[{"id":78003,"name":"Lectures","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"g51c53a1e9df3c74c392ef0f81c39c7aa","items":[{"id":459012,"title":"Introduction","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eSimon Marlow's book on\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"https://simonmar.github.io/pages/pcph.html\" target=\"_blank\"\u003e\u003cspan\u003eParallel and Concurrent Programming in Haskell\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003egives a good explanation of why the topics of this course are interesting. It also makes the same distinction between concurrency and parallelism as that made in this course. We consider only Part I on parallelism in the Haskell part of the course. We will simply call the book PCPH.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eBe inspired by this video of\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"https://skillsmatter.com/skillscasts/1774-talk-by-haskell-expert-simon-peyton-jones\" target=\"_blank\"\u003e\u003cspan\u003eSimon Peyton Jones lecturing on parallel programming in Haskell\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e (Links to an external site.).\u003c/span\u003e\u003c/a\u003e\u003cspan class=\"screenreader-only\"\u003e (Note that you need to register (for free) at Skills Matter to see it.)\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003eThe three papers listed at the end of the first lecture are\n\u003cul\u003e\n\u003cli\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"HaskellSharedMemory.pdf\" href=\"viewer/files/HaskellSharedMemory.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/18420/files/2061680\" data-api-returntype=\"File\"\u003e\u003cspan\u003eHaskell on a Shared-Memory Multiprocessor\u003c/span\u003e\u003c/a\u003e, Harris, Marlow and Peyton Jones, Haskell'05\u003c/li\u003e\n\u003cli\u003e\u003ca class=\"external\" href=\"http://www.cse.chalmers.se/edu/year/2018/course/DAT280_Parallel_Functional_Programming/Papers/FDIP.pdf\" target=\"_blank\"\u003e\u003cspan\u003eFeedback Directed Implicit Parallelism\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e, Harris and Singh, ICFP'07\u003c/li\u003e\n\u003cli\u003e\u003ca class=\"external\" href=\"https://simonmar.github.io/bib/papers/multicore-ghc.pdf\" target=\"_blank\"\u003e\u003cspan\u003eRuntime Support for Multicore Haskell\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e, Marlow, Peyton Jones and Singh, ICFP'09\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMake sure to read the last of these.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003eHere are the \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"Parallel Functional Programming.pdf\" href=\"viewer/files/Parallel%20Functional%20Programming.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/18420/files/2061682\" data-api-returntype=\"File\"\u003eslides.\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","exportId":"gdda5277f4e22fb4e3028ac4ac10c251a"},{"id":459013,"title":"Yet another monad tutorial","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eThis lecture is a beginner's introduction to monads, showing how we can use them to structure code that may fail, return multiple results, or perform I/O, with monadic parsing (and a brief introduction to monad transformers) as an example.\u003c/p\u003e\n\u003cp\u003eslides:\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"Yet Another Monad Tutorial.pdf\" href=\"viewer/files/Yet%20Another%20Monad%20Tutorial.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003e\u0026nbsp;Yet Another Monad Tutorial.pdf\u003c/a\u003e\u003c/p\u003e","exportId":"gb0dd4bccde2e2d314c91335895aaf4e8"},{"id":459014,"title":"Strategies","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eThis lecture considers par and pseq more critically, and concludes that it might be a good idea to separate the control of behaviour relating to parallelisation from the description of the algorithm itself. The idea of Strategies is described in a well-known paper called\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003cspan class=\"instructure_file_holder link_holder\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"strategies93.pdf\" href=\"viewer/files/strategies93.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647965\" data-api-returntype=\"File\"\u003e\u003cspan\u003eAlgorithm + Strategy = Parallelism\u003c/span\u003e\u003c/a\u003e \u003c/span\u003eby Trinder, Hammond, Loidl and Peyton Jones. More recently, Marlow and some of the original authors have updated the idea, in\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003cspan class=\"instructure_file_holder link_holder\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"strategies10.pdf\" href=\"viewer/files/strategies10.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647966\" data-api-returntype=\"File\"\u003e\u003cspan\u003eSeq no more: Better Strategies for Parallel Haskel\u003c/span\u003e\u003cspan\u003el\u003c/span\u003e\u003c/a\u003e\u003c/span\u003e. Take a quick look at the first Strategies paper; it was very influential, and it is interesting to see how it led to the second one. The lecture is based on the newer paper and you should concentrate mostly on that paper. See also PCPH chapters 2 and 3.\u003c/p\u003e\n\u003cp\u003eSlides: \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"Lecture323.pdf\" href=\"viewer/files/Lecture323.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2692881\" data-api-returntype=\"File\"\u003eLecture323.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOther Material:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://hackage.haskell.org/package/parallel-3.2.2.0/docs/Control-Parallel-Strategies.html\" target=\"_blank\"\u003e\u003cspan\u003edocumentation of the Strategies Library\u0026nbsp;\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eis very helpful.\u003c/li\u003e\n\u003cli\u003eThe\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.cse.chalmers.se/~rjmh/Papers/whyfp.pdf\" target=\"_blank\"\u003e\u003cspan\u003elink to Why Functional Programming Matters\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","exportId":"g63e0192f3fd4b54d52423d4fca3e1d60"},{"id":459015,"title":"the Par Monad","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eThis lecture is about a programming model for deterministic parallelism, introduced by Simon Marlow and colleagues. It introduces the Par Monad, a monad for deterministic parallelism, and shows how I-structures are used to exchange information between parallel tasks (or \"blobs\"), see\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2011/01/monad-par.pdf\" target=\"_blank\"\u003e\u003cspan\u003eMarlow's Haskell'11\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003epaper\u003cspan\u003e\u0026nbsp;\u003c/span\u003ewith Ryan Newton and Simon PJ. You should read this paper.\u003c/p\u003e\n\u003cp\u003eTake a look at the\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"IStructures.pdf\" href=\"viewer/files/IStructures.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647986\" data-api-returntype=\"File\"\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"IStructures.pdf\" href=\"viewer/files/IStructures.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647986\" data-api-returntype=\"File\"\u003eI-Structures paper\u003c/a\u003e \u003c/span\u003ereferred to in the lecture (not obligatory but interesting). See PCPH chapter 4.\u003c/p\u003e\n\u003cp\u003eAlso, Phil Wadler's\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003cspan class=\"instructure_file_holder link_holder\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"monadsWadler.pdf\" href=\"https://chalmers.instructure.com/api/v1/canvadoc_session?blob=%7B%22moderated_grading_whitelist%22:null,%22enable_annotations%22:null,%22enrollment_type%22:null,%22anonymous_instructor_annotations%22:null,%22submission_id%22:null,%22user_id%22:125230000000000836,%22attachment_id%22:488172,%22type%22:%22canvadoc%22%7D\u0026amp;hmac=c7fee6010e899fa0a9b78d2b4d6114244823b7cd\"\u003e\"Essence of Functional Programming\"\u003c/a\u003e\u003c/span\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eis a very interesting read, and it covers monads and continuation passing style.\u003c/p\u003e\n\u003cp\u003eThe Par monad is based on Koen Claessen's Poor Man's Concurrency Monad (we call it PMC, see his\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003cspan\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"PMCJFP.pdf\" href=\"viewer/files/PMCJFP.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647952\" data-api-returntype=\"File\"\u003eJFP Pearl\u003c/a\u003e).\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eBefore getting on to the Par monad, we take a look at Petricek's use of monad comprehensions and parallel list comprehensions combined with the Eval monad (see \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"ParMonadPetricek.pdf\" href=\"viewer/files/ParMonadPetricek.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2698617\" data-api-returntype=\"File\"\u003ePetricek's paper\u003c/a\u003e, which I advise you to read). That paper can also help with understanding PMC.\u003c/p\u003e\n\u003cp\u003eSlides:\u003c/p\u003e\n\u003cp\u003e\u003ca class=\"inline_disabled\" href=\"https://docs.google.com/presentation/d/1y2g4D5Wb1Cu1VvH-k0RxeUhvbGpzB6avH20m3VO4AzI/edit?usp=drivesdk\" target=\"_blank\"\u003eKoen's slides about PMC (for info)\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"Lecture423.pdf\" href=\"viewer/files/Lecture423.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2698607\" data-api-returntype=\"File\"\u003eLecture423.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eUncommented Haskell code for playing with the Poor Man's Concurrency Monad \u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"L3.hs\" href=\"viewer/files/L3.hs?canvas_download=1\u0026amp;canvas_qs_wrap=1\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647967\" data-api-returntype=\"File\"\u003eL3.hs\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eComment from Mary: The Par monad provides quite an attractive approach to deterministic parallel programming in Haskell. However, the question of what set of combinators should go on top of this to ease the job of the programmer has not been addressed as much as I expected when we started this course. The github version contains a \u003ca href=\"https://github.com/simonmar/monad-par/blob/master/monad-par-extras/Control/Monad/Par/Combinator.hs\"\u003efile of combinators\u003c/a\u003e but it is very much work in progress. If you find yourself with time on your hands, you might want to think about and implement some combinators. For instance, it would be nice to have combinators that express both how to break up input data and how to control task granularity. There is clearly more research to be done!\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eThe version of the Par monad that Max Algehed (a former student and then TA) has made that allows you to draw pictures of your programs is at\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca class=\"external\" href=\"https://github.com/MaximilianAlgehed/VisPar\" target=\"_blank\"\u003e\u003cspan\u003eVisPar\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","exportId":"gb837439d011f26a8d68ffb77a3399b70"},{"id":459016,"title":"Parallel Programming in Erlang","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cdiv class=\"event-detail-overflow\"\u003e\n\u003cp\u003eThis lecture introduces Erlang for Haskell programmers), taking parallelising quicksort as an example, both within one Erlang VM and distributed across a network. The latest version of the Erlang system can be downloaded from\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.erlang.org/downloads\" target=\"_blank\"\u003e\u003cspan\u003ehere\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e. There is a Windows installer. Many linux versions have an Erlang packagage available, but not necessarily a package suitable for development of Erlang code, and not necessarily the latest version. On Ubuntu, try\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003esudo apt-get install erlang-dev\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf that doesn't work or you can't find an appropriate package, build the VM from source.\u003c/p\u003e\n\u003cp\u003eSlides:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cspan\u003eThe \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"Parallel Programming in Erlang.pdf\" href=\"viewer/files/Parallel%20Programming%20in%20Erlang.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2702726\" data-api-returntype=\"File\"\u003eslides\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\n\u003cli\u003e\u003cspan\u003eA version of foo.erl can be found \u003ca class=\"instructure_file_link inline_disabled\" title=\"foo.erl\" href=\"viewer/files/foo.erl?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2702743\" data-api-returntype=\"File\"\u003ehere\u003c/a\u003e. (This file is provided as-is, in case you want to experiment with the code from the lecture--there are no comments, for example, and there is experimental code that didn't make it into the lecture).\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e","exportId":"gf8960f43af9a6505e59f7a3428062cd0"},{"id":459017,"title":"Robust Erlang","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eThis lecture focusses on the fault tolerance constructs in Erlang--links and system processes--and the motivation for the \"Let It Crash\" philosophy. It introduces supervision trees and the Open Telecoms Platform, and develops a simple generic server.\u003c/p\u003e\n\u003cp\u003eSlides :\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe\u003cspan\u003e\u0026nbsp;\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"Robust Erlang.pdf\" href=\"viewer/files/Robust%20Erlang.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\"\u003e\u003cspan class=\"instructure_file_holder link_holder\"\u003eslides\u003c/span\u003e\u003c/a\u003e\u003c/span\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","exportId":"ga9c92a3037048d56a321e80a020a8b88"},{"id":459018,"title":"Erlang Parallel Search","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eQuickCheck finds faults in software by testing properties in a large number of random test cases. Since test cases are independent of each other, there is scope to speed up fault-finding dramatically using parallelism. But realising those speed-ups in practice requires a careful choice of architecture and some surprising trade-offs. In this lecture I'll tell this story.\u003c/p\u003e\n\u003cp\u003eSlides:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"ErlangParallelSearch.pdf\" href=\"viewer/files/ErlangParallelSearch.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/18420/files/2066230\" data-api-returntype=\"File\"\u003e\u003cspan\u003eslides\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","exportId":"g24126b0ae84df50e8d08b0e8db316fc0"},{"id":459020,"title":"Parallelising Haskell QuickCheck","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cdiv style=\"margin-top: 0; margin-bottom: 0;\"\u003eRobert Krook will talk about parallelization of the Haskell QuickCheck implementation.\u003c/div\u003e\n\u003cdiv style=\"margin-top: 0; margin-bottom: 0;\"\u003e\u003cspan style=\"font-size: 18pt;\"\u003eQuickerCheck!\u003c/span\u003e\u003c/div\u003e\n\u003cdiv style=\"margin-top: 0; margin-bottom: 0;\"\u003e\u003cstrong\u003eAbstract\u003c/strong\u003e:\u003c/div\u003e\n\u003cdiv style=\"margin-top: 0; margin-bottom: 0;\"\u003e\u003ca class=\"inline_disabled\" href=\"https://dl.acm.org/doi/abs/10.1145/351240.351266\" target=\"_blank\"\u003eQuickCheck\u003c/a\u003e is a wonderful tool for finding bugs in your program if you can define your specifications as properties. While QuickCheck is often presented to students using simple examples such as properties on lists or trees, QuickCheck can actually be used to test large, real world systems. Testing such systems can in many cases take a very long time, and you might be tempted to launch multiple instances of QuickCheck to test your properties. One downside with this approach, however, is that if each individual test takes a non-trivial amount of time to execute, shrinking also becomes slow business. Your computer will sound like a spaceship despite just one core being busy!\u003c/div\u003e\n\u003cdiv style=\"margin-top: 0; margin-bottom: 0;\"\u003eModifying the internal machinery of QuickCheck to make use of all the available cores can help speed up the testing process. In this lecture I will go over some very recent work I did on parallelizing the internal testing loop as well as the shrinking loop. In this course you are shown how you can achieve parallelism via the spark pool and the Par monad. To parallelize QuickCheck I use forkIO to spawn threads. I use asynchronous exceptions and MVars to communicate between them.\u003c/div\u003e\n\u003cdiv style=\"margin-top: 0; margin-bottom: 0;\"\u003eWhat initially appeared to be some simple engineering work turned out to challenge me in ways that I did not expect. I will show you some experimental results and things to think about when you run properties in parallel. Tests that may appear to be embarrassingly parallel might actually not be!\u003c/div\u003e\n\u003cp\u003eslides from the talk (animations got messed up, and appear as a single picture with everything overlayed) can be found here: \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"QuickerCheck.pdf\" href=\"viewer/files/Lectures/QuickerCheck.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003eQuickerCheck.pdf\u003c/a\u003e\u003c/p\u003e","exportId":"g552e221d2af7f07e64e7b20ee3821028"},{"id":459021,"title":"Data Parallelism I","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eThis lecture is about Guy Blelloch's seminal work on the NESL programming language, with its associated cost model, on Brent's theorem and on parallel scan as a building block of parallel algorithms.\u003c/p\u003e\n\u003cp\u003eMaterial:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eThe best introduction is to watch\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"https://vimeo.com/album/1468571/video/16541324\" target=\"_blank\"\u003e\u003cspan\u003ethe video of Blelloch's marvellous invited talk at ICFP 2010\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.cs.cmu.edu/~scandal/nesl.html\" target=\"_blank\"\u003e\u003cspan\u003epage about NESL\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003e(including interactive tutorial, papers and information about applications)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eReading:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTo read about Work and Depth, start with\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.cs.cmu.edu/~scandal/cacm/node1.html\" target=\"_blank\"\u003e\u003cspan\u003ethis page\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e. Note that there will very likely be an exam question about work and depth and related topics.\u0026nbsp; So study examples in NESL and the background material!\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eWe advise reading the whole of Blelloch's\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.cs.cmu.edu/~scandal/cacm/cacm2.html\" target=\"_blank\"\u003e\u003cspan\u003eProgramming Parallel Algorithms\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e, CACM 39(3). (Also available as \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"ProgParallelAlgs.pdf\" href=\"viewer/files/ProgParallelAlgs.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2648006\" data-api-returntype=\"File\"\u003epdf\u003c/a\u003e.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSlides:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe\u003cspan\u003e \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"LectureDP123.pdf\" href=\"viewer/files/LectureDP123.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003eslides\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAndrzej Filinksi's NESL interpreter, which calculates work and span (or depth) for you:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.cse.chalmers.se/edu/year/2018/course/DAT280_Parallel_Functional_Programming/Material/DataParallel/unesl.hs\" target=\"_blank\"\u003e\u003cspan\u003einterpreter itself (a Haskell program, see comments at top)\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eA\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.cse.chalmers.se/edu/year/2018/course/DAT280_Parallel_Functional_Programming/Material/DataParallel/toPost.nesl\" target=\"_blank\"\u003e\u003cspan\u003esmall file of example programs (toPost.nesl)\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eA\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.cse.chalmers.se/edu/year/2018/course/DAT280_Parallel_Functional_Programming/Material/DataParallel/exampleRun.txt\" target=\"_blank\"\u003e\u003cspan\u003etext file showing some example uses of the interpreter\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eMany thanks to Andrzej for letting us use his tool.\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","exportId":"g7601c01bad9d5e58c9abff1929645b11"},{"id":459022,"title":"Data Parallelism II Futhark (Troels Henriksen, DIKU)","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eFunctional programming is intuitively a great fit for massively parallel programming, and Blelloch's seminal work on NESL appeared to show exactly how to transform nested data parallelism into efficient flat parallelism. So how come we are not all using functional languages to program our GPUs? In this lecture we will discuss the gap between simply expressing a lot of parallelism, and actually obtaining good performance on real hardware. I will present the design and implementation of the Futhark programming language, which has been carefully restricted (compared to NESL) to permit the construction of an aggressively optimising compiler. We will look at how close Futhark gets to the dream of automatically transforming high-level hardware-agnostic functional parallel code into efficient low-level code, and how to tailor one's parallel programming style to the restrictions imposed by Futhark.\u003c/p\u003e\n\u003cp\u003eRecommended reading (in decreasing order of relevance):\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca class=\"external\" href=\"https://futhark-lang.org/publications/pldi17.pdf\" target=\"_blank\"\u003e\u003cspan\u003eYou are required to read this paper, which outlines the basis of the Futhark implementation strategy\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca class=\"external\" href=\"http://futhark.readthedocs.io/\" target=\"_blank\"\u003e\u003cspan\u003eThe Futhark User's Guide and language reference (for use when doing the lab)\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca class=\"external\" href=\"http://futhark-book.readthedocs.io/\" target=\"_blank\"\u003e\u003cspan\u003eParallel Programming in Futhark (\"the Futhark book\"), although incomplete, is likely the simplest introduction\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca class=\"external\" href=\"https://futhark-lang.org/publications/fhpc17.pdf\" target=\"_blank\"\u003e\u003cspan\u003eThis paper shows a simple example of Futhark's multi-versioned code generation technique\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca class=\"external\" href=\"https://futhark-lang.org/publications/troels-henriksen-phd-thesis.pdf\" target=\"_blank\"\u003e\u003cspan\u003eFor the particularly motivated, the first part of my thesis\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"lectureFuthark23.pdf\" href=\"viewer/files/lectureFuthark23.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003e\u003cspan class=\"instructure_file_holder link_holder\"\u003eslides\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","exportId":"gd3d9b16c8666612956910a70d6b2080a"},{"id":459023,"title":"Data Parallelism III Parallel functional programming  in Java (Peter Sestoft, ITU)","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eIt has long been assumed in academic circles that functional programming, and declarative processing of streams of immutable data, are convenient and effective tools for parallel programming. Evidence for this is now provided, paradoxically, by the object-imperative Java language, whose version 8 (from 2014) supports functional programming, parallelizable stream processing, and parallel array prefix operations. We illustrate some of these features and use them to solve computational problems that are usually handled by (hard to parallelize) for-loops, and also combinatorial problems such as the n-queens problem, using only streams, higher-order functions and recursion. We show that this declarative approach leads to very good performance on shared-memory multicore machines with a near-trivial parallelization effort on this widely used programming platform. We also highlight a few of the warts caused by the embedding in Java. Some of the examples presented are from Sestoft: Java Precisely, 3rd edition, MIT Press 2016.\u003c/p\u003e\n\u003cp\u003eSlides:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"chalmers-parfun-20230504.pdf\" href=\"viewer/files/chalmers-parfun-20230504.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003e\u003cspan class=\"instructure_file_holder link_holder\"\u003eslides\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe following exercise sheet has been provided by Peter Sestoft. It is not compulsory, but you may find it interesting and educational.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"PFPJava-exercise-sheet.pdf\" href=\"viewer/files/PFPJava-exercise-sheet.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647962\" data-api-returntype=\"File\"\u003e\u003cspan class=\"instructure_file_holder link_holder\"\u003eParallel Functional Programming in Java Exercise Sheet\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","exportId":"g723a64f618964d58781b72d6eb5e0c9f"},{"id":459024,"title":"Data Parallelism IV Accelerate (Gabriele Keller, Utrecht University)","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eThis lecture builds on the first two lectures on data parallelism which introduced programming in NESL and Futhark, respectively. \u0026nbsp;We will look at the Haskell embedded language Accelerate. Just like Futhark, it implements NESL's collection oriented programming model, and is also restricted to mostly regular computations. In the second part of the lecture, we will look at implementation aspects, how to generalise the regular data parallel model, and where the challenges are. \u0026nbsp;\u003c/p\u003e\n\u003cp\u003eSlides\u003c/p\u003e\n\u003cp\u003e\u0026nbsp; \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"Chalmers lecture.pdf\" href=\"viewer/files/Chalmers%20lecture.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/18420/files/2061694\" data-api-returntype=\"File\"\u003e.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eReading material\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.acceleratehs.org/examples.html\"\u003eThe Accelerate Project\u0026nbsp;\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://hackage.haskell.org/package/accelerate-1.2.0.1/docs/Data-Array-Accelerate.html\"\u003eDocumentation of the Accelerate library\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","exportId":"g203b9f311a94d54e7f6fe261bbce7d06"},{"id":459025,"title":"Virtual Machines for Functional Languages (Erik Stenman)","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eErik talked about the design of both the BEAM (the virtual machine on which Erlang runs), and of FATE, a virtual machine for the smart contract language Sophia, which is itself implemented in Erlang. His slides can be found \u003ca class=\"inline_disabled\" href=\"https://prezi.com/view/ULD28xH67Z4e0bhS030e/\" target=\"_blank\"\u003ehere\u003c/a\u003e .\u003c/p\u003e","exportId":"g2d0747ac3a74458c2b1143dc3e68bb76"},{"id":459026,"title":"Map Reduce","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eGoogle's Map-Reduce framework has become a popular approach for processing very large datasets in distributed clusters. Although originally implemented in C++, it's connections with functional programming are close: the original inspiration came from the map and reduce functions in LISP; MapReduce is a higher-order function for distributed computing; purely functional behaviour of mappers and reducers is exploited for fault tolerance; it is ideal for implementation in Erlang. This lecture explains what Map-Reduce is, shows a sequential and a simple parallel implementation in Erlang, and discusses the refinements needed to make it work in reality.\u003c/p\u003e\n\u003cp\u003eReading:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eOne of\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca class=\"external\" href=\"http://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf\" target=\"_blank\"\u003e\u003cspan\u003eMapReduce: Simplified Data Processing on Large Clusters\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e, the original paper from 2004.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca class=\"external\" href=\"http://dl.acm.org/citation.cfm?id=1327492\" target=\"_blank\"\u003e\u003cspan\u003eMapReduce: Simplified Data Processing on Large Clusters\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e, a retrospective published in CACM in 2008.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYes, both papers have the same title (and the same authors). What can you do?\u003c/p\u003e\n\u003cp\u003eSlides:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.cse.chalmers.se/edu/year/2018/course/DAT280_Parallel_Functional_Programming/Material/MapReduce/slides.pdf\" target=\"_blank\"\u003e\u003cspan\u003eslides\u003c/span\u003e\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","exportId":"g6041833fc4e48c81f9d70d1cec87c3f3"},{"id":459028,"title":"Databases in the New World","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eNo-SQL databases have become very popular for the kind of scalable applications that Erlang is used for. In this lecture, we introduce the mother of them all, Amazon's Dynamo, and one of its descendants -- Riak, implemented in Erlang by Basho Technologies. We discuss scalability, the CAP theorem, eventual consistency, consistent hashing and the ring, and the mechanisms used to detect, tolerate, and repair inconsistency.\u003c/p\u003e\n\u003cp\u003eReading:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eThe key reference is the Dynamo paper.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eFor amusing and informative background reading, check out\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"https://aphyr.com/posts/288-the-network-is-reliable\" target=\"_blank\"\u003e\u003cspan\u003eThe Network is Reliable (yeah right)\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSlides:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"Databases for the New World.pdf\" href=\"viewer/files/Databases%20for%20the%20New%20World.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\"\u003e\u003cspan class=\"instructure_file_holder link_holder\"\u003eslides\u003c/span\u003e\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","exportId":"g53ade395d7373ecf61f83ff243a57513"},{"id":459029,"title":"Concurrency in the Real World (Richard Carlsson)","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eA presentation of many of the real issues that arise when working with large scale distributed systems in the real world. Richard has long experience with this kind of system, including many years at Klarna, and recent work with blockchain development. He is well known in the Erlang community, contributed to HiPE (the first native code compiler for Erlang), and is the author of very popular libraries such as eunit, the unit test framework for Erlang. He is the designer of the exception handling constructs in Erlang, and recently has returned to language design.\u003c/p\u003e\n\u003cp\u003eHis slides are here: \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"Concurrency 2023.pdf\" href=\"viewer/files/Concurrency%202023.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003eConcurrency 2023.pdf\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","exportId":"g55a49ba8d367048007350aa6b684e92e"},{"id":459032,"title":"Composable Memory Transactions in Haskell","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eThis lecture will introduce Haskell's STM ('software transactional memory') monad, an alternative technique for structuring concurrent programs in Haskell. The lecture is based heavily on \u003ca class=\"inline_disabled\" href=\"https://cs.uwaterloo.ca/~Brecht/courses/702/Possible-Readings/transactional-memory/composable-mem-trans-ppopp-2005.pdf\" target=\"_blank\"\u003ethis paper\u003c/a\u003e, with a section inspired by \u003ca class=\"inline_disabled\" href=\"https://vimeo.com/452222780\" target=\"_blank\"\u003ethis keynote presentation\u003c/a\u003e. The slides are \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"Composable Memory Transactions in Haskell.pdf\" href=\"viewer/files/Composable%20Memory%20Transactions%20in%20Haskell.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003ehere\u003c/a\u003e.\u003c/p\u003e","exportId":"g640d436bfeb8871e3959d19429d4aa8f"}]},{"id":78004,"name":"Labs","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"g92e2eb88b73424a4463e09bcf18e02e1","items":[{"id":459033,"title":"Overview of the Labs","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003ch1 class=\"page-title\"\u003eOverview of Labs\u003c/h1\u003e\n\u003cp\u003e\u003cspan\u003eThere are four compulsory programming (lab) assignments in total. You have to pass all of these to get a pass on the course. There are also some optional programming exercises (which we strongly advise you to do). Some labs have extra assignments. These are for your own pleasure; there are no bonus points awarded. You are\u0026nbsp;\u003c/span\u003e\u003cstrong\u003esupposed to work in pairs\u003c/strong\u003e\u003cspan\u003e, so please find a lab partner! Only under highly unusual circumstances do we allow people not to work in pairs. Please\u0026nbsp;\u003c/span\u003econtact us\u003cspan\u003e\u0026nbsp;in that case. We never allow 3 or more people in a lab group.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eIt is advisable that both students in a group are at a\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003cstrong\u003esimilar level\u003c/strong\u003e. Otherwise, there is a risk that the more experienced student will do most of the work, and the other student will not learn much.\u003c/p\u003e\n\u003cp\u003eIf you need to find a lab partner, please use the\u003cspan\u003e\u0026nbsp;Discussions option in Canvas\u003c/span\u003e\u0026nbsp;to advertise your availability.\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ch3\u003eCompulsory Labs\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003e▷\u003c/span\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eLab A:\u003cspan\u003e\u0026nbsp;\u003c/span\u003eParallel Programming in Haskell\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003e▷\u003c/span\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eLab B:\u003cspan\u003e\u0026nbsp;\u003c/span\u003eParallelizing a Sudoku Solver\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003e▷\u003c/span\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eLab C: Data Parallel Programming\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003e▷\u003c/span\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eLab D: Map-reduce in Erlang\u003c/p\u003e","exportId":"g3f6fb97e7794970b2f50b7a4f8db5ceb"},{"id":459034,"title":"Lab A","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eWhen you are done, please submit your solution using the\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003cspan\u003e\u003ca class=\"inline_disabled\" href=\"https://pfp-lp4-24.fire.cse.chalmers.se/\" target=\"_blank\"\u003eFire system\u003c/a\u003e, see guidelines for submission at the bottom of the page.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eIn this lab assignment, you will get started with parallel programming in Haskell, including the use of\u003cspan\u003e Criterion and Threadscope \u003c/span\u003efor profiling.\u003c/p\u003e\n\u003cp\u003esee the \u003ca title=\"Haskell Installation Instructions\" href=\"pages/gcebf3a087d71851fc48da59126e161c5\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/29110/pages/haskell-installation-instructions\" data-api-returntype=\"Page\"\u003eHaskell Installation\u003c/a\u003e page. \u0026nbsp;It is important to read the advice below on GHC flags, task size etc.!\u003c/p\u003e\n\u003ch3\u003eSetup\u003c/h3\u003e\n\u003cp\u003eFollow the \u003ca title=\"Setup for Lab A\" href=\"pages/gc3d009d1eabc1b87631df86e26ee04ba\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/29110/pages/setup-for-lab-a\" data-api-returntype=\"Page\"\u003einstructions for preparing Lab A\u003c/a\u003e.\u003c/p\u003e\n\u003ch3\u003eAssignment 1\u003c/h3\u003e\n\u003cp\u003eThis first assignment is about parallelising an “embarassingly parallel” function.\u003c/p\u003e\n\u003cp\u003eAn embarassingly parallel function is one that has many separate and non-communicating tasks. In Haskell, it is often a\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003emap\u003c/code\u003e. The file\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.cse.chalmers.se/edu/year/2018/course/DAT280_Parallel_Functional_Programming/Material/given.hs\" target=\"_blank\"\u003e\u003cspan\u003e\u003ccode\u003egiven.hs\u003c/code\u003e\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003econtains the function\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003ejackknife\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003ethat maps the\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003emean\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003efunction over a list of lists (created using\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003eresamples\u003c/code\u003e). The code is borrowed from\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.scs.stanford.edu/11au-cs240h/notes/par-slides.html#(36)\" target=\"_blank\"\u003e\u003cspan\u003ethis lecture\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003e(I think by Bryan O’Sullivan, author of Criterion, the benchmarking tool you will use).\u003c/p\u003e\n\u003cp\u003eYour job is to parallelise that\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003emap\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003ein a number of different ways, and to benchmark and report on your results. (If you get bored with parallelising\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003emap\u003c/code\u003e, you can always move on to\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003eresamples\u003c/code\u003e. I have not tried that!)\u003c/p\u003e\n\u003cp\u003eAt a minimum, you should do the following\u003c/p\u003e\n\u003col type=\"a\"\u003e\n\u003cli\u003e\n\u003cp\u003eParallelise\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003ejackknife\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eusing\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003epar\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eand\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003epseq\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003e(for example by defining a parallel map function that uses\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003epar\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eand\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003epseq\u003c/code\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eParallelise\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003ejackknife\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eusing\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003erpar\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eand\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003erseq\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003efrom the\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003eEval\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003emonad by defining a parallel map function that uses\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003erpar\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eand\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003erseq\u003c/code\u003e. Compare with the built in\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003eparMap\u003c/code\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eParallelise\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003ejackknife\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eusing Strategies. [Comment in response to a question that John got: Here, you are expected to use Strategies without using rpar and rseq directly. So question c is not already solved if you answer question b. (These are all easy questions., by the way.)]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eParallelise\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003ejackknife\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eusing the\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003ePar\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eMonad.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eRemember that\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"https://simonmar.github.io/pages/pcph.html\" target=\"_blank\"\u003e\u003cspan\u003ePCPH\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eis a great source of information and \u003ca class=\"inline_disabled\" href=\"https://github.com/simonmar/parconc-examples\" target=\"_blank\"\u003eexamples\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ch3\u003eAssignment 2\u003c/h3\u003e\n\u003cp\u003eIn Haskell, define a Divide and Conquer higher order function that enables parallelisation of recursive algorithms. The type of this function should be something similar to (but perhaps not identical to)\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003edivConq :: (a -\u0026gt; Bool) -- test if problem is small enough\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; -\u0026gt; (a -\u0026gt; Bool) -- granularity control\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; -\u0026gt; (a -\u0026gt; [a]) -- or (a -\u0026gt; (a,a)), to split the problem into smaller ones\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; -\u0026gt; (a -\u0026gt; b) -- solver for sequential\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; -\u0026gt; ([b] -\u0026gt; b) -- or ((b,b) -\u0026gt; b), merge sub-solutions ...\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; -\u0026gt; a -- input\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; -\u0026gt; b -- output\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eWe suggest using the Par Monad but you may make other choices if you wish. Now, use the pattern to implement two different parallel algorithms, one of which should be sorting on lists. Try to choose a completely new algorithm for the second one, rather than just copying some code from a book or paper. \u003cspan style=\"color: var(--ic-brand-font-color-dark); font-family: inherit; font-size: 1rem;\"\u003eBenchmark your implementations systematically. Report on your results. (Expect only moderate speedups for sorting on lists. If you run out of things to do, you could play with sorting on arrays or other data structures.)\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003eAssignment 3\u003c/h3\u003e\n\u003cp\u003eAs discussed in Chapter 3 of \u003ca class=\"inline_disabled\" href=\"https://simonmar.github.io/pages/pcph.html\" target=\"_blank\"\u003ePCPH\u003c/a\u003e, Haskell programs that work on lazy streams can pose a bit of a problem for parallelisation because there is a risk of losing the nice lazy behaviour. One possible solution is \u003ccode\u003eparBuffer\u003c/code\u003e, which keeps control over the number of available sparks.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eStudy the implementation of \u003ccode\u003eparBuffer\u003c/code\u003e in the \u003ca class=\"inline_disabled\" href=\"https://hackage.haskell.org/package/parallel/docs/Control-Parallel-Strategies.html\" target=\"_blank\"\u003eStrategies library,\u003c/a\u003e and write a brief description of how it works.\u003c/li\u003e\n\u003cli\u003eUsing a suitable example (such as \u003ca class=\"inline_disabled\" href=\"https://github.com/simonmar/parconc-examples/blob/master/sudoku4.hs\" target=\"_blank\"\u003esudoku4.hs\u003c/a\u003e\u0026nbsp; or \u003ca class=\"inline_disabled\" href=\"https://github.com/simonmar/parconc-examples/blob/master/rsa2.hs\" target=\"_blank\"\u003ersa2.hs\u003c/a\u003e\u0026nbsp; from the \u003ca class=\"inline_disabled\" href=\"https://github.com/simonmar/parconc-examples\" target=\"_blank\"\u003ePCPH example code\u003c/a\u003e) or some code of your own, experiment with \u003ccode\u003eparBuffer\u003c/code\u003e and how the resulting dynamic behaviour differs from what you get with \u003ccode\u003eparList\u003c/code\u003e or \u003ccode\u003eparListChunk\u003c/code\u003e. Your report should function as a brief tutorial about \u003ccode\u003eparBuffer\u003c/code\u003e. You should study low level details like heap residency, spark creation, and what the spark pool looks like during the computation. Threadscope provides good facilities for this. If you click Traces near the top left, you can see Spark Creation, Spark Conversion and the Spark Pool. \u0026nbsp;Include suitable screen shots in your report.\u003c/li\u003e\n\u003cli\u003eInvestigate and document the effect of combining chunking with \u003ccode\u003eParBuffer\u003c/code\u003e.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ch3\u003eAdvice on GHC flags, garbage collection, task size etc (Nick Frolov, former TA)\u003c/h3\u003e\n\u003cp\u003eIf you’re not getting speedups, or if the performance of a parallel program is worse than that of a sequential one, make sure that garbage collection is not the bottleneck in your program. If a significant part of your Threadscope plots is GC (orange color), try to run your program pretending you have unlimited memory, so no GC will happen. Set a ridiculously large nursery size with the -A flag (100 Mb will do), this will effectively turn the collector off, as the nursery will never be full, therefore no GC will be needed. To enable this, you need to use the +RTS flag before -A when invoking your program.\u003c/p\u003e\n\u003cp\u003eIf your program actually requires more memory for intermediate values over its runtime, you might want to consider to recycle memory. A small nursery size will cause more frequent GC but also more eager promotion. The former brings an overhead when allocated data doesn’t tend to be short-living, and the latter in the opposite case (if short-living data ended up being promoted to an older generation, it will still have to be collected). A good nursery size should not usually also be larger than L2 cache to exploit locality, but a better one can only be found experimentally. The -H flag (setting the initial heap size) should not be neglected either.\u003c/p\u003e\n\u003cp\u003eWhile the heap will expand if its initial size was not enough, doing so is an extra work for the collector. Set it generously (perhaps, 1 Gb), there is no fault in doing it other than exhausting your RAM. Which, ideally, you shouldn’t do, as swapping is much more expensive than GC, just as serving cache faults from main memory is if the nursery exceeds the cache size.\u003c/p\u003e\n\u003cp\u003eDon’t forget to experiment with depth (or unit of work size, if you prefer that). If you’re getting many fizzled sparks (check on it with the -s flag or in Threadscope), it is a clear sign that your units of work are too small and not worth spawning a thread to do. Remember that to run even a Haskell green thread means tens of instructions, this does not justify an addition of 32-bit integers or a similarly cheap operation. Another cause of fizzled sparks is uneven division of work into chunks, which can also lead to sparked computation results being needed sooner than the corresponding sparks get a chance to be converted. You can see spark size statistics in Threadscope (“Spark sizes” tab).\u003c/p\u003e\n\u003cp\u003eIf you’re wondering why your sequential scan with an “expensive” operator runs much faster than a parallelized version, try to switch off optimization. Some “expensive” operators are not that expensive if GHC takes a good look at them, especially if it sees a chance for aggressive inlining (and there are many indeed, when no sparks are being created).\u003c/p\u003e\n\u003cp\u003e\u003ca name=\"subm\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch3\u003eSubmission\u003c/h3\u003e\n\u003cp\u003eThis lab has two deadlines:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFirst deadline (Wednesday, April 12 at 23:59): You need to have made a serious effort on all obligatory parts of the lab assignment.\u003c/li\u003e\n\u003cli\u003eFinal deadline (Wednesday, April 19 at 23:59): You need to have passed the lab unless you have requested and been given an extension.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eYour submission needs to include the following information:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eYour Haskell file (.hs or .lhs) or files, containing your solution. A single Haskell file is preferred (but that can be awkward when using some libraries). Call it LabAxx where xx is your group number (or something similar if you have several files). Do not submit .o, .hi or .exe files!\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ereport.txt or report.pdf, a file containing brief documentation of what you have done. Submit the files separately (no tar or similar).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eBefore you submit your code, Clean It Up! Remember, submitting clean code is Really Important, and simply the polite thing to do. After you feel you are done, spend some time on cleaning your code; make it simpler, remove unnecessary things, etc. We will reject your solution if it is not clean. Clean code:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDoes not have long lines (\u0026lt; 78 characters)\u003c/li\u003e\n\u003cli\u003eHas a consistent layout (do not use TAB characters in your code)\u003c/li\u003e\n\u003cli\u003eHas type signatures for all top-level functions\u003c/li\u003e\n\u003cli\u003eHas good comments\u003c/li\u003e\n\u003cli\u003eHas no junk (junk is unused code, commented code, unnecessary comments)\u003c/li\u003e\n\u003cli\u003eHas no overly complicated function definitions\u003c/li\u003e\n\u003cli\u003eDoes not contain any repetitive code (copy-and-paste programming)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWhen you are done, please submit using the\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003cspan\u003e\u003ca class=\"inline_disabled\" href=\"https://pfp-lp4-23.fire.cse.chalmers.se/\" target=\"_blank\"\u003eFire system\u003c/a\u003e.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eGood luck!\u003c/p\u003e","exportId":"gb4678c58e4dd96fa7c5b5084a3486973"},{"id":459035,"title":"Lab B","type":"Assignment","indent":0,"locked":false,"submissionTypes":null,"graded":false,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cp\u003eIn this lab assignment, you will speed up a simple Sudoku solver using parallelism.\u003c/p\u003e\n\u003cp\u003eThe assignment\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cspan\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"Sudoku Lab.pdf\" href=\"viewer/files/LabB_2022/Sudoku%20Lab.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647994\" data-api-returntype=\"File\"\u003eSudoku Lab.pdf\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe sequential solver, for you to start from\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca class=\"external\" href=\"http://www.cse.chalmers.se/edu/year/2018/course/DAT280_Parallel_Functional_Programming/Material/Sudoku/sudoku.erl\" target=\"_blank\"\u003e\u003cspan\u003eerl\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eA set of benchmark problems\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca class=\"external\" href=\"http://www.cse.chalmers.se/edu/year/2018/course/DAT280_Parallel_Functional_Programming/Material/Sudoku/problems.txt\" target=\"_blank\"\u003e\u003cspan\u003etxt\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ca name=\"subm\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch3\u003eSubmission\u003c/h3\u003e\n\u003cp\u003eThis lab has two deadlines (see the deadlines in the Fire system):\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFirst deadline: You need to have made a serious effort on all obligatory parts of the lab assignment.\u003c/li\u003e\n\u003cli\u003eFinal deadline: You need to have passed the lab unless you have requested and been given an extension.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eYour submission needs to include the following information:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eYour parallelized code, as an Erlang module.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA file containing a brief description of the methods you used to parallelize your code, together with benchmark output and your analysis of it (see the lab description).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSubmit your lab report PDF and your source code into FIRE (NOT AS AN ARCHIVE).\u003c/p\u003e\n\u003cp\u003eBefore you submit your code, Clean It Up! Remember, submitting clean code is Really Important, and simply the polite thing to do. After you feel you are done, spend some time on cleaning your code; make it simpler, remove unnecessary things, etc. We will reject your solution if it is not clean.\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eWhen you are done, please submit using the Fire system.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eGood luck!\u003c/p\u003e","exportId":"g10743106b5bd86eed4a5f19448a8094b"},{"id":459036,"title":"Lab C","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eIn this lab assignment, you will explore data parallel programming in Futhark.\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eWhen you are done, please submit your solution using the\u003c/span\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003cspan\u003e\u003ca class=\"inline_disabled\" href=\"https://pfp-lp4-24.fire.cse.chalmers.se/\" target=\"_blank\"\u003eFire system\u003c/a\u003e.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eThe assignment\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"FutharkLab23.pdf\" href=\"viewer/files/FutharkLab23.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/29110/files/3378938\" data-api-returntype=\"File\"\u003eLabC23.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eAssociated materials (hints, partially written code etc., notes are from last year's lab but still relevant)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"futhark-lab-notes.pdf\" href=\"viewer/files/futhark-lab-notes.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/29110/files/3378937\" data-api-returntype=\"File\"\u003e\u003cspan class=\"instructure_file_holder link_holder\"\u003efuthark-lab-notes.pdf\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca class=\"instructure_file_link inline_disabled\" title=\"futhark-lab-notes.tar.gz\" href=\"viewer/files/futhark-lab-notes.tar.gz?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/29110/files/3378922\" data-api-returntype=\"File\"\u003efuthark-lab-notes.tar.gz\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca class=\"instructure_file_link inline_disabled\" title=\"ising-handout.tar.gz\" href=\"viewer/files/ising-handout.tar.gz?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/29110/files/3378939\" data-api-returntype=\"File\"\u003eising-handout.tar.gz\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eInstallation instructions for Futhark \u003ca href=\"https://futhark.readthedocs.io/en/latest/installation.html\" target=\"_blank\"\u003ehttps://futhark.readthedocs.io/en/latest/installation.html\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eShould you run into difficulties with installation or with other aspects of Futhark, Troels suggests that you make use of the Futhark Gitter room: \u003ca href=\"https://gitter.im/futhark-lang/Lobby\" target=\"_blank\"\u003ehttps://gitter.im/futhark-lang/Lobby\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eTroels has been very helpful in earlier years, so don't hesitate to contact him.\u003c/p\u003e\n\u003ch3\u003eSubmission\u003c/h3\u003e\n\u003cp\u003eThis lab has two deadlines:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFirst deadline (Friday May 5 at 23:59): You need to have made a serious effort on all obligatory parts of the lab assignment.\u003c/li\u003e\n\u003cli\u003eFinal deadline (Friday, May 12 at 23:59): You need to have passed the lab unless you have requested and been given an extension.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eYour submission needs to include the following information:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eA file containing your Futhark code and a separate report showing Benchmarks, explanations, discussion etc.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eBefore you submit your code, Clean It Up! Remember, submitting clean code is Really Important, and simply the polite thing to do. After you feel you are done, spend some time on cleaning your code; make it simpler, remove unnecessary things, etc. We will reject your solution if it is not clean.\u003c/p\u003e\n\u003cp\u003eWhen you are done, please submit using\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003cspan\u003ethe \u003ca class=\"inline_disabled\" href=\"https://pfp-lp4-23.fire.cse.chalmers.se/\" target=\"_blank\"\u003eFire system.\u003c/a\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eGood luck!\u003c/p\u003e","exportId":"g82babaf006b9a0cb0220f8297aabf26b"},{"id":459037,"title":"Lab D","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eThe goal of this lab is to make the naïve map-reduce implementation presented in the lecture a \u003cem\u003elittle\u003c/em\u003e less naïve. Specifically, we will make it run on multiple Erlang nodes, balance the load between them, and begin to make the code fault-tolerant.\u003c/p\u003e\n\u003ch2\u003eErlang resources\u003c/h2\u003e\n\u003cp\u003eYou will probably need to consult the Erlang documentation during this exercise. You can find the complete documentation here: \u003ca href=\"http://www.erlang.org/doc/\"\u003ehttp://www.erlang.org/doc/\u003c/a\u003e. To find documentation of a particular module, use the list of modules here: \u003ca href=\"http://www.erlang.org/doc/man_index.html\"\u003ehttp://www.erlang.org/doc/man_index.html\u003c/a\u003e. Note that the Windows installer also installs the documentation locally, so if you are using Windows then you can just open the documentation via a link in the Start menu.\u003c/p\u003e\n\u003ch2\u003eConnecting multiple Erlang nodes\u003c/h2\u003e\n\u003cp\u003eThe first step is to set up a network of connected Erlang nodes to play with. This can be done in two ways:\u003c/p\u003e\n\u003ch3\u003eRunning multiple Erlang nodes on one machine\u003c/h3\u003e\n\u003cp\u003eStart several terminal windows/Windows cmd windows, and in each one start a named Erlang shell. Do this using a command such as\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eerl –sname foo\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eon Linux or the Mac, and\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ewerl –sname foo\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eon Windows. (The Windows version starts Erlang in its own window, with some useful menus). The prompt displayed by the Erlang shell will show you what each Erlang node you created is called. For example, on my machine the prompt is\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e(baz@JohnsTablet2012)1\u0026gt;\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThis tells me that the node I created is called \u003cstrong\u003ebaz@JohnsTablet2012\u003c/strong\u003e (an Erlang atom).\u003c/p\u003e\n\u003ch3\u003eRunning Erlang nodes on multiple machines\u003c/h3\u003e\n\u003cp\u003eIt’s more fun using several machines. The procedure is the same as above, but first you \u003cem\u003emust\u003c/em\u003e ensure that all machines use the same cookie. Edit the file .erlang.cookie in your home directory on each machine, and place the same Erlang atom in each one. Then start Erlang nodes as above; as long as the machines are on the same network, then they should be able to find each other. In particular, machines in the labs at Chalmers ought to be able to find each other.\u003c/p\u003e\n\u003ch3\u003eConnecting the nodes together\u003c/h3\u003e\n\u003cp\u003eYour Erlang nodes are not yet connected… calling \u003cstrong\u003enodes()\u003c/strong\u003e on any of them will return the empty list. To connect them, call\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003enet_adm:ping(NodeB).\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eon NodeA (two of your node names). The result should be \u003cstrong\u003epong,\u003c/strong\u003e and calling \u003cstrong\u003enodes()\u003c/strong\u003e afterwards on either node should show you the other. Connect all your nodes in this way. Note that because Erlang builds a complete network, then you need only connect each node to \u003cem\u003eone\u003c/em\u003e other node yourself.\u003c/p\u003e\n\u003ch3\u003eHelp! It doesn’t work\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eOn multiple machines, check that the cookie really is the same on all the nodes. Call \u003cstrong\u003eerlang:get_cookie()\u003c/strong\u003e on each node to make sure.\u003c/li\u003e\n\u003cli\u003eIf NodeA can’t connect to NodeB, try connecting NodeB to NodeA. Sometimes that helps!\u003c/li\u003e\n\u003cli\u003ePerhaps one or more of your machines requires a login before the network connection can be established. In a Windows network, try visiting the Shared Folder on each machine from the others—this may prompt for a password, and once you give the password then Erlang will also be able to connect.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eRemote Procedure Calls\u003c/h2\u003e\n\u003cp\u003eWe’ll start by making remote procedure calls to other nodes. We’ll call io:format, which is Erlang’s version of printf. Try\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003erpc:call(OtherNode,io,format,[“hello”]).\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eYou will find “hello” printed on your \u003cem\u003eown\u003c/em\u003e node! Erlang redirects the output of processes spawned on other nodes back to the original spawning node—so io:format really did run on the other node, but its output was returned to the first one. To force output on the node where io:format runs, we also supply an explicit destination for the output. Try\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003erpc:call(OtherNode,io,format,[user,”hello”,[]]).\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e(where the last argument is the list of values for escapes like ~p in the string… since “hello” contains no escapes, then we pass the empty list). Make sure that the output really does appear on the correct node.\u003c/p\u003e\n\u003ch2\u003eCompiling and loading\u003c/h2\u003e\n\u003cp\u003eLoading code on other nodes is very simple. Write a simple module containing this function:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e-module(foo).\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e-compile(export_all).\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003efoo() -\u0026gt; io:format(user,”hello”,[]).\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eNow you can compile this module in the shell via\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ec(foo).\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eand you can then load it onto all your nodes via the command\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003enl(foo).\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eTry using \u003cstrong\u003erpc:call\u003c/strong\u003e to call \u003cstrong\u003efoo:foo\u003c/strong\u003e on each node, checking that the output appears on the correct node.\u003c/p\u003e\n\u003ch2\u003eNaïve Map-Reduce\u003c/h2\u003e\n\u003cp\u003eYou are given the source code of three of the modules presented in the lecture on map-reduce: a \u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"map_reduce.erl\" href=\"viewer/files/map_reduce.erl?canvas_download=1\u0026amp;canvas_qs_wrap=1\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2648008\" data-api-returntype=\"File\"\u003every simple map-reduce implementation\u003c/a\u003e on one node (both sequential and parallel), and two clients—a \u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"crawl.erl\" href=\"viewer/files/crawl.erl?canvas_download=1\u0026amp;canvas_qs_wrap=1\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647982\" data-api-returntype=\"File\"\u003eweb crawler\u003c/a\u003e and a \u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"page_rank.erl\" href=\"viewer/files/page_rank.erl?canvas_download=1\u0026amp;canvas_qs_wrap=1\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647969\" data-api-returntype=\"File\"\u003epage rank calculator\u003c/a\u003e. These are based on the code presented in the lecture, but the web crawler saves the data it fetches to a file as it runs, to avoid using an excessive amount of RAM.\u003c/p\u003e\n\u003cp\u003eCompile these modules, and ensure that you can crawl a part of the web:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003einets:start().\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003essl:start().\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ecrawl:crawl(“http://www.chalmers.se/”,3).\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e(You may choose any URL to crawl from). You will no doubt see some error and warning messages--ignore them.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eWARNING: \u003c/strong\u003ethis code appears not to work any more under Windows. The Erlang VM crashes (with no error message) during the crawl, which should \u003cem\u003enever\u003c/em\u003e happen. If you are a Windows user, you can instead run the code on Ubuntu under WSL, which works without a problem.\u003c/p\u003e\n\u003cp\u003eCrawling 3 levels deep from the Chalmers URL takes about 30 seconds on my desktop computer, and gathers around 250MB of data. If you crawl from a different URL, ensure you collect at least 100MB of data, so that the page-ranking algorithm takes appreciable time to execute.\u003c/p\u003e\n\u003cp\u003eThe page rank calculator uses the information collected by the web crawler, assuming that the output of the web crawler has been saved in a \u003cem\u003edets \u003c/em\u003efile—a file that contains a set of key-value pairs. You can find the documentation of \u003ccode\u003edets \u003c/code\u003ehere (\u003ca href=\"http://www.erlang.org/doc/man/dets.html\"\u003ehttp://www.erlang.org/doc/man/dets.html\u003c/a\u003e) –and there is quite a lot of it—but you will only need a few functions from this module.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003edets:open_file\u003c/strong\u003e—which opens a dets file\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003edets:close\u003c/strong\u003e—which closes it\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003edets:insert\u003c/strong\u003e—which inserts a list of key-value pairs into the file\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003edets:lookup\u003c/strong\u003e—which returns a list of all the key-value pairs with a given key\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe web crawler should have saved its output in a dets file called \u003ccode\u003eweb.dat\u003c/code\u003e; check that the page ranking algorithm works (by running \u003ccode\u003epage_rank:page_rank()\u003c/code\u003e, which takes about thirty seconds to run on my desktop). Then copy \u003ccode\u003eweb.dat\u003c/code\u003e onto all your nodes—this will enable you to distribute the page-rank computation across your network.\u003c/p\u003e\n\u003ch2\u003eDistributing Map-Reduce\u003c/h2\u003e\n\u003cp\u003eModify the parallel map-reduce implementation so that it spawns worker processes on all of your nodes. Measure the performance of the page-ranking algorithm with the original parallel version, and your new distributed version.\u003c/p\u003e\n\u003ch2\u003eLoad-balancing Map-Reduce\u003c/h2\u003e\n\u003cp\u003eOf course it is not really sensible to spawn all the worker processes at the same time. Instead, we should start enough workers to keep all the nodes busy, then send each node new work as it completes its previous job. Write a \u003cem\u003eworker pool\u003c/em\u003e function which, given a list of 0-ary functions, returns a list of their results, distributing the work across the connected nodes in this way. That is, \u003cem\u003esemantically\u003c/em\u003e \u003cstrong\u003eworker_pool(Funs) -\u0026gt; [Fun() || Fun \u0026lt;- Funs]\u003c/strong\u003e, but the implementation should make use of all the nodes in your network. A good approach is to start several worker processes on each node, each of which keeps requesting a new function to call, then calling it and returning its result to the master, until no more work remains to be done. Modify the map-reduce implementation again to make use of your worker pool in both the map and the reduce phases. Measure the performance of page ranking with your new distributed map-reduce… is it faster?\u003c/p\u003e\n\u003ch2\u003eFault-tolerant Map-Reduce\u003c/h2\u003e\n\u003cp\u003eEnhance your worker-pool to monitor the state of the worker processes, so that if a worker should die, then its work is reassigned to a new worker. Test your fault tolerance by killing one of your Erlang nodes (not the master) while the page-ranking algorithm is running. It should complete, with the same results, despite the failure.\u003c/p\u003e\n\u003ch2\u003eHand ins\u003c/h2\u003e\n\u003cp\u003eYou should submit the code of the three versions of map-reduce described above, together with your performance measurements, using the Fire system. Describe your set-up: were you running on one machine or several, how much web data were you searching? What conclusions would you draw from this exercise?\u003c/p\u003e\n\u003cp\u003eThe deadlines are in the Fire system.\u003c/p\u003e\n\u003ch2\u003eMore\u003c/h2\u003e\n\u003cp\u003eA full map-reduce implementation does a lot more than this, of course. The next step would be to avoid sending all the data via the master—the results of each mapper should be sent \u003cem\u003edirectly\u003c/em\u003e to the right reducer… although this introduces a lot more complexity. Something to experiment with later, perhaps?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e","exportId":"gd180a06f7e81d386d9dddddc2b9c9827"}]},{"id":78005,"name":"Exercises","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"g0a7d742cef6c85da8df81c0821e26543","items":[{"id":459038,"title":"Threadscope demo","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003e\u003cspan style=\"text-decoration: underline;\"\u003eThreadscope Demo\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eIn this exercise session (on Friday 24/3 at 15:15) we are going to look more closely at Threadscope and how we can use it to analyse the parallel performance of our Haskell programs.\u003c/p\u003e\n\u003cp\u003eWe will look at associated topics, such as weak head normal form (WHNF), normal form (NF), thunks etc.\u003c/p\u003e","exportId":"gf8b7084246e73011eb89da67b5e3bb74"},{"id":459039,"title":"Erlang Parallelism (SAT) Demo","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eOn Friday April 8 there is a demo on parallelization of a SAT solver in Erlang. The demo will take place in EB and starts at 15.\u0026nbsp;\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003eZoom info:\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003ehttps://chalmers.zoom.us/j/65643666016\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003ePassword: sat-demo\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003eMaterial: \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"sat_parallel.pdf\" href=\"viewer/files/Demos/sat_parallel.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/18420/files/2116286\" data-api-returntype=\"File\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"sat_parallel.pdf\" href=\"viewer/files/Demos/sat_parallel.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/18420/files/2116286\" data-api-returntype=\"File\"\u003esat_parallel.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003e\u003ca class=\"instructure_file_link inline_disabled\" title=\"sat_2022_04_08.erl\" href=\"viewer/files/Demos/sat_2022_04_08.erl?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/18420/files/2116298\" data-api-returntype=\"File\"\u003esat_2022_04_08.erl\u003c/a\u003e\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"formula.txt\" href=\"viewer/files/Demos/formula.txt?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003eformula.txt\u003c/a\u003e\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"harder.txt\" href=\"viewer/files/Demos/harder.txt?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003eharder.txt\u003c/a\u003e\u003c/p\u003e","exportId":"ga8161d866586b69a4b88b291b6e29e57"}]},{"id":78006,"name":"Installation Instructions","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"ga800b74ec186afba13d85c01e2c65e7e","items":[{"id":459040,"title":"Haskell Installation Instructions","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eYou will need to install the following tools and libraries for this course:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u0026nbsp;The Haskell build tool \u003ca class=\"inline_disabled\" href=\"https://docs.haskellstack.org/en/stable/README/\" target=\"_blank\"\u003estack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca class=\"inline_disabled\" href=\"https://docs.haskellstack.org/en/stable/README/\" target=\"_blank\"\u003e\u003c/a\u003eThe Haskell libraries \u003ca class=\"inline_disabled\" style=\"font-family: inherit; font-size: 1rem;\" href=\"https://hackage.haskell.org/package/criterion\" target=\"_blank\"\u003ecriterion\u003c/a\u003e, \u003ca class=\"inline_disabled\" href=\"https://hackage.haskell.org/package/parallel-3.2.2.0\" target=\"_blank\"\u003eparallel\u003c/a\u003e, and \u003ca class=\"inline_disabled\" href=\"https://hackage.haskell.org/package/monad-par\" target=\"_blank\"\u003emonad-par\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca class=\"inline_disabled\" style=\"font-family: inherit; font-size: 1rem;\" href=\"https://hackage.haskell.org/package/criterion\" target=\"_blank\"\u003e\u003c/a\u003eThe Haskell tool \u003ca class=\"inline_disabled\" style=\"font-family: inherit; font-size: 1rem;\" href=\"https://github.com/haskell/ThreadScope\" target=\"_blank\"\u003eThreadScope\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003eStack\u003c/h4\u003e\n\u003cp\u003eTo install stack, follow the instructions on the \u003ca class=\"inline_disabled\" href=\"https://docs.haskellstack.org/en/stable/README/#how-to-install\" target=\"_blank\"\u003ewebpage\u003c/a\u003e. Stack isolates every Haskell project you work on to have its own toolchain. Please see \u003ca class=\"inline_disabled\" href=\"https://docs.haskellstack.org/en/stable/README/#quick-start-guide\" target=\"_blank\"\u003ethis page\u003c/a\u003e for details.\u003c/p\u003e\n\u003cp\u003eFor instructions on how to set up and configure a stack project see the \u003ca class=\"inline_disabled\" href=\"pages/gc3d009d1eabc1b87631df86e26ee04ba\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/pages/setup-for-lab-a:\" data-api-returntype=\"Page\"\u003eLabA setup instructions\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSee the \u003ca class=\"inline_disabled\" href=\"https://docs.haskellstack.org/en/stable/GUIDE/\" target=\"_blank\"\u003estack guide\u003c/a\u003e for more detailed information on how stack works.\u003c/p\u003e\n\u003ch4\u003eHaskell Libraries\u003c/h4\u003e\n\u003cp\u003eTo use e.g. the criterion library in a project, simply add \u003ccode\u003e\u003cspan style=\"font-family: terminal, monaco;\"\u003ecriterion\u003c/span\u003e\u003c/code\u003e to the \u003ccode\u003e\u003cspan style=\"font-family: terminal, monaco;\"\u003ebuild-depends\u003c/span\u003e\u003c/code\u003e list in your project's cabal file.\u003c/p\u003e\n\u003ch4\u003eThreadScope\u003c/h4\u003e\n\u003cp\u003eTo install ThreadScope either download one of the pre-prepared binaries (instructions on \u003ca class=\"inline_disabled\" href=\"https://github.com/haskell/ThreadScope\" target=\"_blank\"\u003eGitHub\u003c/a\u003e, don't forget to follow the instructions on the page) or follow the installation instructions on the \u003ca class=\"inline_disabled\" href=\"https://github.com/haskell/ThreadScope\" target=\"_blank\"\u003eGitHub\u003c/a\u003e page. To build from GitHub you need to clone the repository, install the GTK+2 dependency and then issue stack install.\u003c/p\u003e\n\u003ch4\u003eInstalling ThreadScope on Windows\u003c/h4\u003e\n\u003cp\u003eDownload the pre-compiled binary for Windows from \u003ca href=\"https://github.com/haskell/ThreadScope/releases\" target=\"_blank\"\u003ehttps://github.com/haskell/ThreadScope/releases\u003c/a\u003e. This binary must be run under MSYS2 and requires GTK2 to work.\u0026nbsp;Install MSYS2 from \u003ca href=\"https://www.msys2.org/\" target=\"_blank\"\u003ehttps://www.msys2.org/\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eBeware this gotcha:\u003c/strong\u003e MSYS2 installs\u0026nbsp;\u003cem\u003ethree different\u003c/em\u003e shells, and on installation offers to start the MSYS shell for you.\u0026nbsp;\u003cem\u003eThis is the wrong one\u003c/em\u003e, and if you try to follow the GTK2 installation instructions in this shell, they will not work. Instead, \u003cstrong\u003e\u003cem\u003eyou must explicitly start the MinGW 64-bit shell\u003c/em\u003e\u003c/strong\u003e (in your Start menu). In this shell, the installation command for GTK2\u003c/p\u003e\n\u003cpre\u003epacman -S \u003cspan class=\"pl-smi\"\u003e$MINGW_PACKAGE_PREFIX\u003c/span\u003e-gtk2\u003c/pre\u003e\n\u003cp\u003eworks, and you will then be able to invoke threadscope.exe from the command line in that shell. (Double-clicking on it will not work; you have to start it from the command line).\u003c/p\u003e","exportId":"gcebf3a087d71851fc48da59126e161c5"},{"id":459041,"title":"Erlang Installation Instructions","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003eYou will need one primary tools for this part of the course.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eYou need an Erlang distribution that you can install by clicking on this \u003ca class=\"inline_disabled\" href=\"https://www.erlang-solutions.com/downloads/\" target=\"_blank\"\u003elink\u003c/a\u003e and following the instructions.\u003c/li\u003e\n\u003c/ul\u003e","exportId":"gd760e672980067b5051886fa3e649c8b"}]}],"pages":[{"exportId":"g640d436bfeb8871e3959d19429d4aa8f","title":"Composable Memory Transactions in Haskell","type":"WikiPage","content":"\u003cp\u003eThis lecture will introduce Haskell's STM ('software transactional memory') monad, an alternative technique for structuring concurrent programs in Haskell. The lecture is based heavily on \u003ca class=\"inline_disabled\" href=\"https://cs.uwaterloo.ca/~Brecht/courses/702/Possible-Readings/transactional-memory/composable-mem-trans-ppopp-2005.pdf\" target=\"_blank\"\u003ethis paper\u003c/a\u003e, with a section inspired by \u003ca class=\"inline_disabled\" href=\"https://vimeo.com/452222780\" target=\"_blank\"\u003ethis keynote presentation\u003c/a\u003e. The slides are \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"Composable Memory Transactions in Haskell.pdf\" href=\"viewer/files/Composable%20Memory%20Transactions%20in%20Haskell.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003ehere\u003c/a\u003e.\u003c/p\u003e","frontPage":false},{"exportId":"g55a49ba8d367048007350aa6b684e92e","title":"Concurrency in the Real World (Richard Carlsson)","type":"WikiPage","content":"\u003cp\u003eA presentation of many of the real issues that arise when working with large scale distributed systems in the real world. Richard has long experience with this kind of system, including many years at Klarna, and recent work with blockchain development. He is well known in the Erlang community, contributed to HiPE (the first native code compiler for Erlang), and is the author of very popular libraries such as eunit, the unit test framework for Erlang. He is the designer of the exception handling constructs in Erlang, and recently has returned to language design.\u003c/p\u003e\n\u003cp\u003eHis slides are here: \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"Concurrency 2023.pdf\" href=\"viewer/files/Concurrency%202023.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003eConcurrency 2023.pdf\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","frontPage":false},{"exportId":"g7601c01bad9d5e58c9abff1929645b11","title":"Data Parallelism I","type":"WikiPage","content":"\u003cp\u003eThis lecture is about Guy Blelloch's seminal work on the NESL programming language, with its associated cost model, on Brent's theorem and on parallel scan as a building block of parallel algorithms.\u003c/p\u003e\n\u003cp\u003eMaterial:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eThe best introduction is to watch\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"https://vimeo.com/album/1468571/video/16541324\" target=\"_blank\"\u003e\u003cspan\u003ethe video of Blelloch's marvellous invited talk at ICFP 2010\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.cs.cmu.edu/~scandal/nesl.html\" target=\"_blank\"\u003e\u003cspan\u003epage about NESL\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003e(including interactive tutorial, papers and information about applications)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eReading:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTo read about Work and Depth, start with\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.cs.cmu.edu/~scandal/cacm/node1.html\" target=\"_blank\"\u003e\u003cspan\u003ethis page\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e. Note that there will very likely be an exam question about work and depth and related topics.\u0026nbsp; So study examples in NESL and the background material!\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eWe advise reading the whole of Blelloch's\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.cs.cmu.edu/~scandal/cacm/cacm2.html\" target=\"_blank\"\u003e\u003cspan\u003eProgramming Parallel Algorithms\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e, CACM 39(3). (Also available as \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"ProgParallelAlgs.pdf\" href=\"viewer/files/ProgParallelAlgs.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2648006\" data-api-returntype=\"File\"\u003epdf\u003c/a\u003e.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSlides:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe\u003cspan\u003e \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"LectureDP123.pdf\" href=\"viewer/files/LectureDP123.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003eslides\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAndrzej Filinksi's NESL interpreter, which calculates work and span (or depth) for you:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.cse.chalmers.se/edu/year/2018/course/DAT280_Parallel_Functional_Programming/Material/DataParallel/unesl.hs\" target=\"_blank\"\u003e\u003cspan\u003einterpreter itself (a Haskell program, see comments at top)\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eA\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.cse.chalmers.se/edu/year/2018/course/DAT280_Parallel_Functional_Programming/Material/DataParallel/toPost.nesl\" target=\"_blank\"\u003e\u003cspan\u003esmall file of example programs (toPost.nesl)\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eA\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.cse.chalmers.se/edu/year/2018/course/DAT280_Parallel_Functional_Programming/Material/DataParallel/exampleRun.txt\" target=\"_blank\"\u003e\u003cspan\u003etext file showing some example uses of the interpreter\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eMany thanks to Andrzej for letting us use his tool.\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","frontPage":false},{"exportId":"gd3d9b16c8666612956910a70d6b2080a","title":"Data Parallelism II Futhark (Troels Henriksen, DIKU)","type":"WikiPage","content":"\u003cp\u003eFunctional programming is intuitively a great fit for massively parallel programming, and Blelloch's seminal work on NESL appeared to show exactly how to transform nested data parallelism into efficient flat parallelism. So how come we are not all using functional languages to program our GPUs? In this lecture we will discuss the gap between simply expressing a lot of parallelism, and actually obtaining good performance on real hardware. I will present the design and implementation of the Futhark programming language, which has been carefully restricted (compared to NESL) to permit the construction of an aggressively optimising compiler. We will look at how close Futhark gets to the dream of automatically transforming high-level hardware-agnostic functional parallel code into efficient low-level code, and how to tailor one's parallel programming style to the restrictions imposed by Futhark.\u003c/p\u003e\n\u003cp\u003eRecommended reading (in decreasing order of relevance):\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca class=\"external\" href=\"https://futhark-lang.org/publications/pldi17.pdf\" target=\"_blank\"\u003e\u003cspan\u003eYou are required to read this paper, which outlines the basis of the Futhark implementation strategy\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca class=\"external\" href=\"http://futhark.readthedocs.io/\" target=\"_blank\"\u003e\u003cspan\u003eThe Futhark User's Guide and language reference (for use when doing the lab)\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca class=\"external\" href=\"http://futhark-book.readthedocs.io/\" target=\"_blank\"\u003e\u003cspan\u003eParallel Programming in Futhark (\"the Futhark book\"), although incomplete, is likely the simplest introduction\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca class=\"external\" href=\"https://futhark-lang.org/publications/fhpc17.pdf\" target=\"_blank\"\u003e\u003cspan\u003eThis paper shows a simple example of Futhark's multi-versioned code generation technique\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca class=\"external\" href=\"https://futhark-lang.org/publications/troels-henriksen-phd-thesis.pdf\" target=\"_blank\"\u003e\u003cspan\u003eFor the particularly motivated, the first part of my thesis\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"lectureFuthark23.pdf\" href=\"viewer/files/lectureFuthark23.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003e\u003cspan class=\"instructure_file_holder link_holder\"\u003eslides\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","frontPage":false},{"exportId":"g723a64f618964d58781b72d6eb5e0c9f","title":"Data Parallelism III Parallel functional programming  in Java (Peter Sestoft, ITU)","type":"WikiPage","content":"\u003cp\u003eIt has long been assumed in academic circles that functional programming, and declarative processing of streams of immutable data, are convenient and effective tools for parallel programming. Evidence for this is now provided, paradoxically, by the object-imperative Java language, whose version 8 (from 2014) supports functional programming, parallelizable stream processing, and parallel array prefix operations. We illustrate some of these features and use them to solve computational problems that are usually handled by (hard to parallelize) for-loops, and also combinatorial problems such as the n-queens problem, using only streams, higher-order functions and recursion. We show that this declarative approach leads to very good performance on shared-memory multicore machines with a near-trivial parallelization effort on this widely used programming platform. We also highlight a few of the warts caused by the embedding in Java. Some of the examples presented are from Sestoft: Java Precisely, 3rd edition, MIT Press 2016.\u003c/p\u003e\n\u003cp\u003eSlides:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"chalmers-parfun-20230504.pdf\" href=\"viewer/files/chalmers-parfun-20230504.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003e\u003cspan class=\"instructure_file_holder link_holder\"\u003eslides\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe following exercise sheet has been provided by Peter Sestoft. It is not compulsory, but you may find it interesting and educational.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"PFPJava-exercise-sheet.pdf\" href=\"viewer/files/PFPJava-exercise-sheet.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647962\" data-api-returntype=\"File\"\u003e\u003cspan class=\"instructure_file_holder link_holder\"\u003eParallel Functional Programming in Java Exercise Sheet\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","frontPage":false},{"exportId":"g203b9f311a94d54e7f6fe261bbce7d06","title":"Data Parallelism IV Accelerate (Gabriele Keller, Utrecht University)","type":"WikiPage","content":"\u003cp\u003eThis lecture builds on the first two lectures on data parallelism which introduced programming in NESL and Futhark, respectively. \u0026nbsp;We will look at the Haskell embedded language Accelerate. Just like Futhark, it implements NESL's collection oriented programming model, and is also restricted to mostly regular computations. In the second part of the lecture, we will look at implementation aspects, how to generalise the regular data parallel model, and where the challenges are. \u0026nbsp;\u003c/p\u003e\n\u003cp\u003eSlides\u003c/p\u003e\n\u003cp\u003e\u0026nbsp; \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"Chalmers lecture.pdf\" href=\"viewer/files/Chalmers%20lecture.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/18420/files/2061694\" data-api-returntype=\"File\"\u003e.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eReading material\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.acceleratehs.org/examples.html\"\u003eThe Accelerate Project\u0026nbsp;\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://hackage.haskell.org/package/accelerate-1.2.0.1/docs/Data-Array-Accelerate.html\"\u003eDocumentation of the Accelerate library\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","frontPage":false},{"exportId":"g53ade395d7373ecf61f83ff243a57513","title":"Databases in the New World","type":"WikiPage","content":"\u003cp\u003eNo-SQL databases have become very popular for the kind of scalable applications that Erlang is used for. In this lecture, we introduce the mother of them all, Amazon's Dynamo, and one of its descendants -- Riak, implemented in Erlang by Basho Technologies. We discuss scalability, the CAP theorem, eventual consistency, consistent hashing and the ring, and the mechanisms used to detect, tolerate, and repair inconsistency.\u003c/p\u003e\n\u003cp\u003eReading:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eThe key reference is the Dynamo paper.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eFor amusing and informative background reading, check out\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"https://aphyr.com/posts/288-the-network-is-reliable\" target=\"_blank\"\u003e\u003cspan\u003eThe Network is Reliable (yeah right)\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSlides:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"Databases for the New World.pdf\" href=\"viewer/files/Databases%20for%20the%20New%20World.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\"\u003e\u003cspan class=\"instructure_file_holder link_holder\"\u003eslides\u003c/span\u003e\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","frontPage":false},{"exportId":"gd760e672980067b5051886fa3e649c8b","title":"Erlang Installation Instructions","type":"WikiPage","content":"\u003cp\u003eYou will need one primary tools for this part of the course.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eYou need an Erlang distribution that you can install by clicking on this \u003ca class=\"inline_disabled\" href=\"https://www.erlang-solutions.com/downloads/\" target=\"_blank\"\u003elink\u003c/a\u003e and following the instructions.\u003c/li\u003e\n\u003c/ul\u003e","frontPage":false},{"exportId":"g24126b0ae84df50e8d08b0e8db316fc0","title":"Erlang Parallel Search","type":"WikiPage","content":"\u003cp\u003eQuickCheck finds faults in software by testing properties in a large number of random test cases. Since test cases are independent of each other, there is scope to speed up fault-finding dramatically using parallelism. But realising those speed-ups in practice requires a careful choice of architecture and some surprising trade-offs. In this lecture I'll tell this story.\u003c/p\u003e\n\u003cp\u003eSlides:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"ErlangParallelSearch.pdf\" href=\"viewer/files/ErlangParallelSearch.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/18420/files/2066230\" data-api-returntype=\"File\"\u003e\u003cspan\u003eslides\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","frontPage":false},{"exportId":"ga8161d866586b69a4b88b291b6e29e57","title":"Erlang Parallelism (SAT) Demo","type":"WikiPage","content":"\u003cp\u003eOn Friday April 8 there is a demo on parallelization of a SAT solver in Erlang. The demo will take place in EB and starts at 15.\u0026nbsp;\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003eZoom info:\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003ehttps://chalmers.zoom.us/j/65643666016\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003ePassword: sat-demo\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003eMaterial: \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"sat_parallel.pdf\" href=\"viewer/files/Demos/sat_parallel.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/18420/files/2116286\" data-api-returntype=\"File\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"sat_parallel.pdf\" href=\"viewer/files/Demos/sat_parallel.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/18420/files/2116286\" data-api-returntype=\"File\"\u003esat_parallel.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003e\u003ca class=\"instructure_file_link inline_disabled\" title=\"sat_2022_04_08.erl\" href=\"viewer/files/Demos/sat_2022_04_08.erl?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/18420/files/2116298\" data-api-returntype=\"File\"\u003esat_2022_04_08.erl\u003c/a\u003e\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"formula.txt\" href=\"viewer/files/Demos/formula.txt?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003eformula.txt\u003c/a\u003e\u003c/p\u003e\n\u003cp style=\"text-indent: 0px; margin: 0px;\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"harder.txt\" href=\"viewer/files/Demos/harder.txt?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003eharder.txt\u003c/a\u003e\u003c/p\u003e","frontPage":false},{"exportId":"gcebf3a087d71851fc48da59126e161c5","title":"Haskell Installation Instructions","type":"WikiPage","content":"\u003cp\u003eYou will need to install the following tools and libraries for this course:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u0026nbsp;The Haskell build tool \u003ca class=\"inline_disabled\" href=\"https://docs.haskellstack.org/en/stable/README/\" target=\"_blank\"\u003estack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca class=\"inline_disabled\" href=\"https://docs.haskellstack.org/en/stable/README/\" target=\"_blank\"\u003e\u003c/a\u003eThe Haskell libraries \u003ca class=\"inline_disabled\" style=\"font-family: inherit; font-size: 1rem;\" href=\"https://hackage.haskell.org/package/criterion\" target=\"_blank\"\u003ecriterion\u003c/a\u003e, \u003ca class=\"inline_disabled\" href=\"https://hackage.haskell.org/package/parallel-3.2.2.0\" target=\"_blank\"\u003eparallel\u003c/a\u003e, and \u003ca class=\"inline_disabled\" href=\"https://hackage.haskell.org/package/monad-par\" target=\"_blank\"\u003emonad-par\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca class=\"inline_disabled\" style=\"font-family: inherit; font-size: 1rem;\" href=\"https://hackage.haskell.org/package/criterion\" target=\"_blank\"\u003e\u003c/a\u003eThe Haskell tool \u003ca class=\"inline_disabled\" style=\"font-family: inherit; font-size: 1rem;\" href=\"https://github.com/haskell/ThreadScope\" target=\"_blank\"\u003eThreadScope\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003eStack\u003c/h4\u003e\n\u003cp\u003eTo install stack, follow the instructions on the \u003ca class=\"inline_disabled\" href=\"https://docs.haskellstack.org/en/stable/README/#how-to-install\" target=\"_blank\"\u003ewebpage\u003c/a\u003e. Stack isolates every Haskell project you work on to have its own toolchain. Please see \u003ca class=\"inline_disabled\" href=\"https://docs.haskellstack.org/en/stable/README/#quick-start-guide\" target=\"_blank\"\u003ethis page\u003c/a\u003e for details.\u003c/p\u003e\n\u003cp\u003eFor instructions on how to set up and configure a stack project see the \u003ca class=\"inline_disabled\" href=\"pages/gc3d009d1eabc1b87631df86e26ee04ba\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/pages/setup-for-lab-a:\" data-api-returntype=\"Page\"\u003eLabA setup instructions\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSee the \u003ca class=\"inline_disabled\" href=\"https://docs.haskellstack.org/en/stable/GUIDE/\" target=\"_blank\"\u003estack guide\u003c/a\u003e for more detailed information on how stack works.\u003c/p\u003e\n\u003ch4\u003eHaskell Libraries\u003c/h4\u003e\n\u003cp\u003eTo use e.g. the criterion library in a project, simply add \u003ccode\u003e\u003cspan style=\"font-family: terminal, monaco;\"\u003ecriterion\u003c/span\u003e\u003c/code\u003e to the \u003ccode\u003e\u003cspan style=\"font-family: terminal, monaco;\"\u003ebuild-depends\u003c/span\u003e\u003c/code\u003e list in your project's cabal file.\u003c/p\u003e\n\u003ch4\u003eThreadScope\u003c/h4\u003e\n\u003cp\u003eTo install ThreadScope either download one of the pre-prepared binaries (instructions on \u003ca class=\"inline_disabled\" href=\"https://github.com/haskell/ThreadScope\" target=\"_blank\"\u003eGitHub\u003c/a\u003e, don't forget to follow the instructions on the page) or follow the installation instructions on the \u003ca class=\"inline_disabled\" href=\"https://github.com/haskell/ThreadScope\" target=\"_blank\"\u003eGitHub\u003c/a\u003e page. To build from GitHub you need to clone the repository, install the GTK+2 dependency and then issue stack install.\u003c/p\u003e\n\u003ch4\u003eInstalling ThreadScope on Windows\u003c/h4\u003e\n\u003cp\u003eDownload the pre-compiled binary for Windows from \u003ca href=\"https://github.com/haskell/ThreadScope/releases\" target=\"_blank\"\u003ehttps://github.com/haskell/ThreadScope/releases\u003c/a\u003e. This binary must be run under MSYS2 and requires GTK2 to work.\u0026nbsp;Install MSYS2 from \u003ca href=\"https://www.msys2.org/\" target=\"_blank\"\u003ehttps://www.msys2.org/\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eBeware this gotcha:\u003c/strong\u003e MSYS2 installs\u0026nbsp;\u003cem\u003ethree different\u003c/em\u003e shells, and on installation offers to start the MSYS shell for you.\u0026nbsp;\u003cem\u003eThis is the wrong one\u003c/em\u003e, and if you try to follow the GTK2 installation instructions in this shell, they will not work. Instead, \u003cstrong\u003e\u003cem\u003eyou must explicitly start the MinGW 64-bit shell\u003c/em\u003e\u003c/strong\u003e (in your Start menu). In this shell, the installation command for GTK2\u003c/p\u003e\n\u003cpre\u003epacman -S \u003cspan class=\"pl-smi\"\u003e$MINGW_PACKAGE_PREFIX\u003c/span\u003e-gtk2\u003c/pre\u003e\n\u003cp\u003eworks, and you will then be able to invoke threadscope.exe from the command line in that shell. (Double-clicking on it will not work; you have to start it from the command line).\u003c/p\u003e","frontPage":false},{"exportId":"gdda5277f4e22fb4e3028ac4ac10c251a","title":"Introduction","type":"WikiPage","content":"\u003cp\u003eSimon Marlow's book on\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"https://simonmar.github.io/pages/pcph.html\" target=\"_blank\"\u003e\u003cspan\u003eParallel and Concurrent Programming in Haskell\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003egives a good explanation of why the topics of this course are interesting. It also makes the same distinction between concurrency and parallelism as that made in this course. We consider only Part I on parallelism in the Haskell part of the course. We will simply call the book PCPH.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eBe inspired by this video of\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"https://skillsmatter.com/skillscasts/1774-talk-by-haskell-expert-simon-peyton-jones\" target=\"_blank\"\u003e\u003cspan\u003eSimon Peyton Jones lecturing on parallel programming in Haskell\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e (Links to an external site.).\u003c/span\u003e\u003c/a\u003e\u003cspan class=\"screenreader-only\"\u003e (Note that you need to register (for free) at Skills Matter to see it.)\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003eThe three papers listed at the end of the first lecture are\n\u003cul\u003e\n\u003cli\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"HaskellSharedMemory.pdf\" href=\"viewer/files/HaskellSharedMemory.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/18420/files/2061680\" data-api-returntype=\"File\"\u003e\u003cspan\u003eHaskell on a Shared-Memory Multiprocessor\u003c/span\u003e\u003c/a\u003e, Harris, Marlow and Peyton Jones, Haskell'05\u003c/li\u003e\n\u003cli\u003e\u003ca class=\"external\" href=\"http://www.cse.chalmers.se/edu/year/2018/course/DAT280_Parallel_Functional_Programming/Papers/FDIP.pdf\" target=\"_blank\"\u003e\u003cspan\u003eFeedback Directed Implicit Parallelism\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e, Harris and Singh, ICFP'07\u003c/li\u003e\n\u003cli\u003e\u003ca class=\"external\" href=\"https://simonmar.github.io/bib/papers/multicore-ghc.pdf\" target=\"_blank\"\u003e\u003cspan\u003eRuntime Support for Multicore Haskell\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e, Marlow, Peyton Jones and Singh, ICFP'09\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMake sure to read the last of these.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003eHere are the \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"Parallel Functional Programming.pdf\" href=\"viewer/files/Parallel%20Functional%20Programming.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/18420/files/2061682\" data-api-returntype=\"File\"\u003eslides.\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","frontPage":false},{"exportId":"gb4678c58e4dd96fa7c5b5084a3486973","title":"Lab A","type":"WikiPage","content":"\u003cp\u003eWhen you are done, please submit your solution using the\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003cspan\u003e\u003ca class=\"inline_disabled\" href=\"https://pfp-lp4-24.fire.cse.chalmers.se/\" target=\"_blank\"\u003eFire system\u003c/a\u003e, see guidelines for submission at the bottom of the page.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eIn this lab assignment, you will get started with parallel programming in Haskell, including the use of\u003cspan\u003e Criterion and Threadscope \u003c/span\u003efor profiling.\u003c/p\u003e\n\u003cp\u003esee the \u003ca title=\"Haskell Installation Instructions\" href=\"pages/gcebf3a087d71851fc48da59126e161c5\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/29110/pages/haskell-installation-instructions\" data-api-returntype=\"Page\"\u003eHaskell Installation\u003c/a\u003e page. \u0026nbsp;It is important to read the advice below on GHC flags, task size etc.!\u003c/p\u003e\n\u003ch3\u003eSetup\u003c/h3\u003e\n\u003cp\u003eFollow the \u003ca title=\"Setup for Lab A\" href=\"pages/gc3d009d1eabc1b87631df86e26ee04ba\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/29110/pages/setup-for-lab-a\" data-api-returntype=\"Page\"\u003einstructions for preparing Lab A\u003c/a\u003e.\u003c/p\u003e\n\u003ch3\u003eAssignment 1\u003c/h3\u003e\n\u003cp\u003eThis first assignment is about parallelising an “embarassingly parallel” function.\u003c/p\u003e\n\u003cp\u003eAn embarassingly parallel function is one that has many separate and non-communicating tasks. In Haskell, it is often a\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003emap\u003c/code\u003e. The file\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.cse.chalmers.se/edu/year/2018/course/DAT280_Parallel_Functional_Programming/Material/given.hs\" target=\"_blank\"\u003e\u003cspan\u003e\u003ccode\u003egiven.hs\u003c/code\u003e\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003econtains the function\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003ejackknife\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003ethat maps the\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003emean\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003efunction over a list of lists (created using\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003eresamples\u003c/code\u003e). The code is borrowed from\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.scs.stanford.edu/11au-cs240h/notes/par-slides.html#(36)\" target=\"_blank\"\u003e\u003cspan\u003ethis lecture\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003e(I think by Bryan O’Sullivan, author of Criterion, the benchmarking tool you will use).\u003c/p\u003e\n\u003cp\u003eYour job is to parallelise that\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003emap\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003ein a number of different ways, and to benchmark and report on your results. (If you get bored with parallelising\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003emap\u003c/code\u003e, you can always move on to\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003eresamples\u003c/code\u003e. I have not tried that!)\u003c/p\u003e\n\u003cp\u003eAt a minimum, you should do the following\u003c/p\u003e\n\u003col type=\"a\"\u003e\n\u003cli\u003e\n\u003cp\u003eParallelise\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003ejackknife\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eusing\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003epar\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eand\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003epseq\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003e(for example by defining a parallel map function that uses\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003epar\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eand\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003epseq\u003c/code\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eParallelise\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003ejackknife\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eusing\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003erpar\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eand\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003erseq\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003efrom the\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003eEval\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003emonad by defining a parallel map function that uses\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003erpar\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eand\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003erseq\u003c/code\u003e. Compare with the built in\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003eparMap\u003c/code\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eParallelise\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003ejackknife\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eusing Strategies. [Comment in response to a question that John got: Here, you are expected to use Strategies without using rpar and rseq directly. So question c is not already solved if you answer question b. (These are all easy questions., by the way.)]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eParallelise\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003ejackknife\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eusing the\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003ePar\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eMonad.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eRemember that\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"https://simonmar.github.io/pages/pcph.html\" target=\"_blank\"\u003e\u003cspan\u003ePCPH\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eis a great source of information and \u003ca class=\"inline_disabled\" href=\"https://github.com/simonmar/parconc-examples\" target=\"_blank\"\u003eexamples\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ch3\u003eAssignment 2\u003c/h3\u003e\n\u003cp\u003eIn Haskell, define a Divide and Conquer higher order function that enables parallelisation of recursive algorithms. The type of this function should be something similar to (but perhaps not identical to)\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003edivConq :: (a -\u0026gt; Bool) -- test if problem is small enough\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; -\u0026gt; (a -\u0026gt; Bool) -- granularity control\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; -\u0026gt; (a -\u0026gt; [a]) -- or (a -\u0026gt; (a,a)), to split the problem into smaller ones\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; -\u0026gt; (a -\u0026gt; b) -- solver for sequential\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; -\u0026gt; ([b] -\u0026gt; b) -- or ((b,b) -\u0026gt; b), merge sub-solutions ...\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; -\u0026gt; a -- input\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; -\u0026gt; b -- output\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eWe suggest using the Par Monad but you may make other choices if you wish. Now, use the pattern to implement two different parallel algorithms, one of which should be sorting on lists. Try to choose a completely new algorithm for the second one, rather than just copying some code from a book or paper. \u003cspan style=\"color: var(--ic-brand-font-color-dark); font-family: inherit; font-size: 1rem;\"\u003eBenchmark your implementations systematically. Report on your results. (Expect only moderate speedups for sorting on lists. If you run out of things to do, you could play with sorting on arrays or other data structures.)\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003eAssignment 3\u003c/h3\u003e\n\u003cp\u003eAs discussed in Chapter 3 of \u003ca class=\"inline_disabled\" href=\"https://simonmar.github.io/pages/pcph.html\" target=\"_blank\"\u003ePCPH\u003c/a\u003e, Haskell programs that work on lazy streams can pose a bit of a problem for parallelisation because there is a risk of losing the nice lazy behaviour. One possible solution is \u003ccode\u003eparBuffer\u003c/code\u003e, which keeps control over the number of available sparks.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eStudy the implementation of \u003ccode\u003eparBuffer\u003c/code\u003e in the \u003ca class=\"inline_disabled\" href=\"https://hackage.haskell.org/package/parallel/docs/Control-Parallel-Strategies.html\" target=\"_blank\"\u003eStrategies library,\u003c/a\u003e and write a brief description of how it works.\u003c/li\u003e\n\u003cli\u003eUsing a suitable example (such as \u003ca class=\"inline_disabled\" href=\"https://github.com/simonmar/parconc-examples/blob/master/sudoku4.hs\" target=\"_blank\"\u003esudoku4.hs\u003c/a\u003e\u0026nbsp; or \u003ca class=\"inline_disabled\" href=\"https://github.com/simonmar/parconc-examples/blob/master/rsa2.hs\" target=\"_blank\"\u003ersa2.hs\u003c/a\u003e\u0026nbsp; from the \u003ca class=\"inline_disabled\" href=\"https://github.com/simonmar/parconc-examples\" target=\"_blank\"\u003ePCPH example code\u003c/a\u003e) or some code of your own, experiment with \u003ccode\u003eparBuffer\u003c/code\u003e and how the resulting dynamic behaviour differs from what you get with \u003ccode\u003eparList\u003c/code\u003e or \u003ccode\u003eparListChunk\u003c/code\u003e. Your report should function as a brief tutorial about \u003ccode\u003eparBuffer\u003c/code\u003e. You should study low level details like heap residency, spark creation, and what the spark pool looks like during the computation. Threadscope provides good facilities for this. If you click Traces near the top left, you can see Spark Creation, Spark Conversion and the Spark Pool. \u0026nbsp;Include suitable screen shots in your report.\u003c/li\u003e\n\u003cli\u003eInvestigate and document the effect of combining chunking with \u003ccode\u003eParBuffer\u003c/code\u003e.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ch3\u003eAdvice on GHC flags, garbage collection, task size etc (Nick Frolov, former TA)\u003c/h3\u003e\n\u003cp\u003eIf you’re not getting speedups, or if the performance of a parallel program is worse than that of a sequential one, make sure that garbage collection is not the bottleneck in your program. If a significant part of your Threadscope plots is GC (orange color), try to run your program pretending you have unlimited memory, so no GC will happen. Set a ridiculously large nursery size with the -A flag (100 Mb will do), this will effectively turn the collector off, as the nursery will never be full, therefore no GC will be needed. To enable this, you need to use the +RTS flag before -A when invoking your program.\u003c/p\u003e\n\u003cp\u003eIf your program actually requires more memory for intermediate values over its runtime, you might want to consider to recycle memory. A small nursery size will cause more frequent GC but also more eager promotion. The former brings an overhead when allocated data doesn’t tend to be short-living, and the latter in the opposite case (if short-living data ended up being promoted to an older generation, it will still have to be collected). A good nursery size should not usually also be larger than L2 cache to exploit locality, but a better one can only be found experimentally. The -H flag (setting the initial heap size) should not be neglected either.\u003c/p\u003e\n\u003cp\u003eWhile the heap will expand if its initial size was not enough, doing so is an extra work for the collector. Set it generously (perhaps, 1 Gb), there is no fault in doing it other than exhausting your RAM. Which, ideally, you shouldn’t do, as swapping is much more expensive than GC, just as serving cache faults from main memory is if the nursery exceeds the cache size.\u003c/p\u003e\n\u003cp\u003eDon’t forget to experiment with depth (or unit of work size, if you prefer that). If you’re getting many fizzled sparks (check on it with the -s flag or in Threadscope), it is a clear sign that your units of work are too small and not worth spawning a thread to do. Remember that to run even a Haskell green thread means tens of instructions, this does not justify an addition of 32-bit integers or a similarly cheap operation. Another cause of fizzled sparks is uneven division of work into chunks, which can also lead to sparked computation results being needed sooner than the corresponding sparks get a chance to be converted. You can see spark size statistics in Threadscope (“Spark sizes” tab).\u003c/p\u003e\n\u003cp\u003eIf you’re wondering why your sequential scan with an “expensive” operator runs much faster than a parallelized version, try to switch off optimization. Some “expensive” operators are not that expensive if GHC takes a good look at them, especially if it sees a chance for aggressive inlining (and there are many indeed, when no sparks are being created).\u003c/p\u003e\n\u003cp\u003e\u003ca name=\"subm\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch3\u003eSubmission\u003c/h3\u003e\n\u003cp\u003eThis lab has two deadlines:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFirst deadline (Wednesday, April 12 at 23:59): You need to have made a serious effort on all obligatory parts of the lab assignment.\u003c/li\u003e\n\u003cli\u003eFinal deadline (Wednesday, April 19 at 23:59): You need to have passed the lab unless you have requested and been given an extension.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eYour submission needs to include the following information:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eYour Haskell file (.hs or .lhs) or files, containing your solution. A single Haskell file is preferred (but that can be awkward when using some libraries). Call it LabAxx where xx is your group number (or something similar if you have several files). Do not submit .o, .hi or .exe files!\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ereport.txt or report.pdf, a file containing brief documentation of what you have done. Submit the files separately (no tar or similar).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eBefore you submit your code, Clean It Up! Remember, submitting clean code is Really Important, and simply the polite thing to do. After you feel you are done, spend some time on cleaning your code; make it simpler, remove unnecessary things, etc. We will reject your solution if it is not clean. Clean code:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDoes not have long lines (\u0026lt; 78 characters)\u003c/li\u003e\n\u003cli\u003eHas a consistent layout (do not use TAB characters in your code)\u003c/li\u003e\n\u003cli\u003eHas type signatures for all top-level functions\u003c/li\u003e\n\u003cli\u003eHas good comments\u003c/li\u003e\n\u003cli\u003eHas no junk (junk is unused code, commented code, unnecessary comments)\u003c/li\u003e\n\u003cli\u003eHas no overly complicated function definitions\u003c/li\u003e\n\u003cli\u003eDoes not contain any repetitive code (copy-and-paste programming)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWhen you are done, please submit using the\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003cspan\u003e\u003ca class=\"inline_disabled\" href=\"https://pfp-lp4-23.fire.cse.chalmers.se/\" target=\"_blank\"\u003eFire system\u003c/a\u003e.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eGood luck!\u003c/p\u003e","frontPage":false},{"exportId":"g82babaf006b9a0cb0220f8297aabf26b","title":"Lab C","type":"WikiPage","content":"\u003cp\u003eIn this lab assignment, you will explore data parallel programming in Futhark.\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eWhen you are done, please submit your solution using the\u003c/span\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003cspan\u003e\u003ca class=\"inline_disabled\" href=\"https://pfp-lp4-24.fire.cse.chalmers.se/\" target=\"_blank\"\u003eFire system\u003c/a\u003e.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eThe assignment\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"FutharkLab23.pdf\" href=\"viewer/files/FutharkLab23.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/29110/files/3378938\" data-api-returntype=\"File\"\u003eLabC23.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eAssociated materials (hints, partially written code etc., notes are from last year's lab but still relevant)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"futhark-lab-notes.pdf\" href=\"viewer/files/futhark-lab-notes.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/29110/files/3378937\" data-api-returntype=\"File\"\u003e\u003cspan class=\"instructure_file_holder link_holder\"\u003efuthark-lab-notes.pdf\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca class=\"instructure_file_link inline_disabled\" title=\"futhark-lab-notes.tar.gz\" href=\"viewer/files/futhark-lab-notes.tar.gz?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/29110/files/3378922\" data-api-returntype=\"File\"\u003efuthark-lab-notes.tar.gz\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca class=\"instructure_file_link inline_disabled\" title=\"ising-handout.tar.gz\" href=\"viewer/files/ising-handout.tar.gz?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/29110/files/3378939\" data-api-returntype=\"File\"\u003eising-handout.tar.gz\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eInstallation instructions for Futhark \u003ca href=\"https://futhark.readthedocs.io/en/latest/installation.html\" target=\"_blank\"\u003ehttps://futhark.readthedocs.io/en/latest/installation.html\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eShould you run into difficulties with installation or with other aspects of Futhark, Troels suggests that you make use of the Futhark Gitter room: \u003ca href=\"https://gitter.im/futhark-lang/Lobby\" target=\"_blank\"\u003ehttps://gitter.im/futhark-lang/Lobby\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eTroels has been very helpful in earlier years, so don't hesitate to contact him.\u003c/p\u003e\n\u003ch3\u003eSubmission\u003c/h3\u003e\n\u003cp\u003eThis lab has two deadlines:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFirst deadline (Friday May 5 at 23:59): You need to have made a serious effort on all obligatory parts of the lab assignment.\u003c/li\u003e\n\u003cli\u003eFinal deadline (Friday, May 12 at 23:59): You need to have passed the lab unless you have requested and been given an extension.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eYour submission needs to include the following information:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eA file containing your Futhark code and a separate report showing Benchmarks, explanations, discussion etc.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eBefore you submit your code, Clean It Up! Remember, submitting clean code is Really Important, and simply the polite thing to do. After you feel you are done, spend some time on cleaning your code; make it simpler, remove unnecessary things, etc. We will reject your solution if it is not clean.\u003c/p\u003e\n\u003cp\u003eWhen you are done, please submit using\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003cspan\u003ethe \u003ca class=\"inline_disabled\" href=\"https://pfp-lp4-23.fire.cse.chalmers.se/\" target=\"_blank\"\u003eFire system.\u003c/a\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eGood luck!\u003c/p\u003e","frontPage":false},{"exportId":"gd180a06f7e81d386d9dddddc2b9c9827","title":"Lab D","type":"WikiPage","content":"\u003cp\u003eThe goal of this lab is to make the naïve map-reduce implementation presented in the lecture a \u003cem\u003elittle\u003c/em\u003e less naïve. Specifically, we will make it run on multiple Erlang nodes, balance the load between them, and begin to make the code fault-tolerant.\u003c/p\u003e\n\u003ch2\u003eErlang resources\u003c/h2\u003e\n\u003cp\u003eYou will probably need to consult the Erlang documentation during this exercise. You can find the complete documentation here: \u003ca href=\"http://www.erlang.org/doc/\"\u003ehttp://www.erlang.org/doc/\u003c/a\u003e. To find documentation of a particular module, use the list of modules here: \u003ca href=\"http://www.erlang.org/doc/man_index.html\"\u003ehttp://www.erlang.org/doc/man_index.html\u003c/a\u003e. Note that the Windows installer also installs the documentation locally, so if you are using Windows then you can just open the documentation via a link in the Start menu.\u003c/p\u003e\n\u003ch2\u003eConnecting multiple Erlang nodes\u003c/h2\u003e\n\u003cp\u003eThe first step is to set up a network of connected Erlang nodes to play with. This can be done in two ways:\u003c/p\u003e\n\u003ch3\u003eRunning multiple Erlang nodes on one machine\u003c/h3\u003e\n\u003cp\u003eStart several terminal windows/Windows cmd windows, and in each one start a named Erlang shell. Do this using a command such as\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eerl –sname foo\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eon Linux or the Mac, and\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ewerl –sname foo\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eon Windows. (The Windows version starts Erlang in its own window, with some useful menus). The prompt displayed by the Erlang shell will show you what each Erlang node you created is called. For example, on my machine the prompt is\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e(baz@JohnsTablet2012)1\u0026gt;\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThis tells me that the node I created is called \u003cstrong\u003ebaz@JohnsTablet2012\u003c/strong\u003e (an Erlang atom).\u003c/p\u003e\n\u003ch3\u003eRunning Erlang nodes on multiple machines\u003c/h3\u003e\n\u003cp\u003eIt’s more fun using several machines. The procedure is the same as above, but first you \u003cem\u003emust\u003c/em\u003e ensure that all machines use the same cookie. Edit the file .erlang.cookie in your home directory on each machine, and place the same Erlang atom in each one. Then start Erlang nodes as above; as long as the machines are on the same network, then they should be able to find each other. In particular, machines in the labs at Chalmers ought to be able to find each other.\u003c/p\u003e\n\u003ch3\u003eConnecting the nodes together\u003c/h3\u003e\n\u003cp\u003eYour Erlang nodes are not yet connected… calling \u003cstrong\u003enodes()\u003c/strong\u003e on any of them will return the empty list. To connect them, call\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003enet_adm:ping(NodeB).\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eon NodeA (two of your node names). The result should be \u003cstrong\u003epong,\u003c/strong\u003e and calling \u003cstrong\u003enodes()\u003c/strong\u003e afterwards on either node should show you the other. Connect all your nodes in this way. Note that because Erlang builds a complete network, then you need only connect each node to \u003cem\u003eone\u003c/em\u003e other node yourself.\u003c/p\u003e\n\u003ch3\u003eHelp! It doesn’t work\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eOn multiple machines, check that the cookie really is the same on all the nodes. Call \u003cstrong\u003eerlang:get_cookie()\u003c/strong\u003e on each node to make sure.\u003c/li\u003e\n\u003cli\u003eIf NodeA can’t connect to NodeB, try connecting NodeB to NodeA. Sometimes that helps!\u003c/li\u003e\n\u003cli\u003ePerhaps one or more of your machines requires a login before the network connection can be established. In a Windows network, try visiting the Shared Folder on each machine from the others—this may prompt for a password, and once you give the password then Erlang will also be able to connect.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eRemote Procedure Calls\u003c/h2\u003e\n\u003cp\u003eWe’ll start by making remote procedure calls to other nodes. We’ll call io:format, which is Erlang’s version of printf. Try\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003erpc:call(OtherNode,io,format,[“hello”]).\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eYou will find “hello” printed on your \u003cem\u003eown\u003c/em\u003e node! Erlang redirects the output of processes spawned on other nodes back to the original spawning node—so io:format really did run on the other node, but its output was returned to the first one. To force output on the node where io:format runs, we also supply an explicit destination for the output. Try\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003erpc:call(OtherNode,io,format,[user,”hello”,[]]).\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e(where the last argument is the list of values for escapes like ~p in the string… since “hello” contains no escapes, then we pass the empty list). Make sure that the output really does appear on the correct node.\u003c/p\u003e\n\u003ch2\u003eCompiling and loading\u003c/h2\u003e\n\u003cp\u003eLoading code on other nodes is very simple. Write a simple module containing this function:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e-module(foo).\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e-compile(export_all).\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003efoo() -\u0026gt; io:format(user,”hello”,[]).\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eNow you can compile this module in the shell via\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ec(foo).\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eand you can then load it onto all your nodes via the command\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003enl(foo).\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eTry using \u003cstrong\u003erpc:call\u003c/strong\u003e to call \u003cstrong\u003efoo:foo\u003c/strong\u003e on each node, checking that the output appears on the correct node.\u003c/p\u003e\n\u003ch2\u003eNaïve Map-Reduce\u003c/h2\u003e\n\u003cp\u003eYou are given the source code of three of the modules presented in the lecture on map-reduce: a \u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"map_reduce.erl\" href=\"viewer/files/map_reduce.erl?canvas_download=1\u0026amp;canvas_qs_wrap=1\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2648008\" data-api-returntype=\"File\"\u003every simple map-reduce implementation\u003c/a\u003e on one node (both sequential and parallel), and two clients—a \u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"crawl.erl\" href=\"viewer/files/crawl.erl?canvas_download=1\u0026amp;canvas_qs_wrap=1\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647982\" data-api-returntype=\"File\"\u003eweb crawler\u003c/a\u003e and a \u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"page_rank.erl\" href=\"viewer/files/page_rank.erl?canvas_download=1\u0026amp;canvas_qs_wrap=1\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647969\" data-api-returntype=\"File\"\u003epage rank calculator\u003c/a\u003e. These are based on the code presented in the lecture, but the web crawler saves the data it fetches to a file as it runs, to avoid using an excessive amount of RAM.\u003c/p\u003e\n\u003cp\u003eCompile these modules, and ensure that you can crawl a part of the web:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003einets:start().\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003essl:start().\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ecrawl:crawl(“http://www.chalmers.se/”,3).\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e(You may choose any URL to crawl from). You will no doubt see some error and warning messages--ignore them.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eWARNING: \u003c/strong\u003ethis code appears not to work any more under Windows. The Erlang VM crashes (with no error message) during the crawl, which should \u003cem\u003enever\u003c/em\u003e happen. If you are a Windows user, you can instead run the code on Ubuntu under WSL, which works without a problem.\u003c/p\u003e\n\u003cp\u003eCrawling 3 levels deep from the Chalmers URL takes about 30 seconds on my desktop computer, and gathers around 250MB of data. If you crawl from a different URL, ensure you collect at least 100MB of data, so that the page-ranking algorithm takes appreciable time to execute.\u003c/p\u003e\n\u003cp\u003eThe page rank calculator uses the information collected by the web crawler, assuming that the output of the web crawler has been saved in a \u003cem\u003edets \u003c/em\u003efile—a file that contains a set of key-value pairs. You can find the documentation of \u003ccode\u003edets \u003c/code\u003ehere (\u003ca href=\"http://www.erlang.org/doc/man/dets.html\"\u003ehttp://www.erlang.org/doc/man/dets.html\u003c/a\u003e) –and there is quite a lot of it—but you will only need a few functions from this module.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003edets:open_file\u003c/strong\u003e—which opens a dets file\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003edets:close\u003c/strong\u003e—which closes it\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003edets:insert\u003c/strong\u003e—which inserts a list of key-value pairs into the file\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003edets:lookup\u003c/strong\u003e—which returns a list of all the key-value pairs with a given key\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe web crawler should have saved its output in a dets file called \u003ccode\u003eweb.dat\u003c/code\u003e; check that the page ranking algorithm works (by running \u003ccode\u003epage_rank:page_rank()\u003c/code\u003e, which takes about thirty seconds to run on my desktop). Then copy \u003ccode\u003eweb.dat\u003c/code\u003e onto all your nodes—this will enable you to distribute the page-rank computation across your network.\u003c/p\u003e\n\u003ch2\u003eDistributing Map-Reduce\u003c/h2\u003e\n\u003cp\u003eModify the parallel map-reduce implementation so that it spawns worker processes on all of your nodes. Measure the performance of the page-ranking algorithm with the original parallel version, and your new distributed version.\u003c/p\u003e\n\u003ch2\u003eLoad-balancing Map-Reduce\u003c/h2\u003e\n\u003cp\u003eOf course it is not really sensible to spawn all the worker processes at the same time. Instead, we should start enough workers to keep all the nodes busy, then send each node new work as it completes its previous job. Write a \u003cem\u003eworker pool\u003c/em\u003e function which, given a list of 0-ary functions, returns a list of their results, distributing the work across the connected nodes in this way. That is, \u003cem\u003esemantically\u003c/em\u003e \u003cstrong\u003eworker_pool(Funs) -\u0026gt; [Fun() || Fun \u0026lt;- Funs]\u003c/strong\u003e, but the implementation should make use of all the nodes in your network. A good approach is to start several worker processes on each node, each of which keeps requesting a new function to call, then calling it and returning its result to the master, until no more work remains to be done. Modify the map-reduce implementation again to make use of your worker pool in both the map and the reduce phases. Measure the performance of page ranking with your new distributed map-reduce… is it faster?\u003c/p\u003e\n\u003ch2\u003eFault-tolerant Map-Reduce\u003c/h2\u003e\n\u003cp\u003eEnhance your worker-pool to monitor the state of the worker processes, so that if a worker should die, then its work is reassigned to a new worker. Test your fault tolerance by killing one of your Erlang nodes (not the master) while the page-ranking algorithm is running. It should complete, with the same results, despite the failure.\u003c/p\u003e\n\u003ch2\u003eHand ins\u003c/h2\u003e\n\u003cp\u003eYou should submit the code of the three versions of map-reduce described above, together with your performance measurements, using the Fire system. Describe your set-up: were you running on one machine or several, how much web data were you searching? What conclusions would you draw from this exercise?\u003c/p\u003e\n\u003cp\u003eThe deadlines are in the Fire system.\u003c/p\u003e\n\u003ch2\u003eMore\u003c/h2\u003e\n\u003cp\u003eA full map-reduce implementation does a lot more than this, of course. The next step would be to avoid sending all the data via the master—the results of each mapper should be sent \u003cem\u003edirectly\u003c/em\u003e to the right reducer… although this introduces a lot more complexity. Something to experiment with later, perhaps?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u0026nbsp;\u003c/strong\u003e\u003c/p\u003e","frontPage":false},{"exportId":"g6041833fc4e48c81f9d70d1cec87c3f3","title":"Map Reduce","type":"WikiPage","content":"\u003cp\u003eGoogle's Map-Reduce framework has become a popular approach for processing very large datasets in distributed clusters. Although originally implemented in C++, it's connections with functional programming are close: the original inspiration came from the map and reduce functions in LISP; MapReduce is a higher-order function for distributed computing; purely functional behaviour of mappers and reducers is exploited for fault tolerance; it is ideal for implementation in Erlang. This lecture explains what Map-Reduce is, shows a sequential and a simple parallel implementation in Erlang, and discusses the refinements needed to make it work in reality.\u003c/p\u003e\n\u003cp\u003eReading:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eOne of\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca class=\"external\" href=\"http://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf\" target=\"_blank\"\u003e\u003cspan\u003eMapReduce: Simplified Data Processing on Large Clusters\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e, the original paper from 2004.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca class=\"external\" href=\"http://dl.acm.org/citation.cfm?id=1327492\" target=\"_blank\"\u003e\u003cspan\u003eMapReduce: Simplified Data Processing on Large Clusters\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e, a retrospective published in CACM in 2008.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYes, both papers have the same title (and the same authors). What can you do?\u003c/p\u003e\n\u003cp\u003eSlides:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.cse.chalmers.se/edu/year/2018/course/DAT280_Parallel_Functional_Programming/Material/MapReduce/slides.pdf\" target=\"_blank\"\u003e\u003cspan\u003eslides\u003c/span\u003e\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","frontPage":false},{"exportId":"g3f6fb97e7794970b2f50b7a4f8db5ceb","title":"Overview of the Labs","type":"WikiPage","content":"\u003ch1 class=\"page-title\"\u003eOverview of Labs\u003c/h1\u003e\n\u003cp\u003e\u003cspan\u003eThere are four compulsory programming (lab) assignments in total. You have to pass all of these to get a pass on the course. There are also some optional programming exercises (which we strongly advise you to do). Some labs have extra assignments. These are for your own pleasure; there are no bonus points awarded. You are\u0026nbsp;\u003c/span\u003e\u003cstrong\u003esupposed to work in pairs\u003c/strong\u003e\u003cspan\u003e, so please find a lab partner! Only under highly unusual circumstances do we allow people not to work in pairs. Please\u0026nbsp;\u003c/span\u003econtact us\u003cspan\u003e\u0026nbsp;in that case. We never allow 3 or more people in a lab group.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eIt is advisable that both students in a group are at a\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003cstrong\u003esimilar level\u003c/strong\u003e. Otherwise, there is a risk that the more experienced student will do most of the work, and the other student will not learn much.\u003c/p\u003e\n\u003cp\u003eIf you need to find a lab partner, please use the\u003cspan\u003e\u0026nbsp;Discussions option in Canvas\u003c/span\u003e\u0026nbsp;to advertise your availability.\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ch3\u003eCompulsory Labs\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003e▷\u003c/span\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eLab A:\u003cspan\u003e\u0026nbsp;\u003c/span\u003eParallel Programming in Haskell\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003e▷\u003c/span\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eLab B:\u003cspan\u003e\u0026nbsp;\u003c/span\u003eParallelizing a Sudoku Solver\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003e▷\u003c/span\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eLab C: Data Parallel Programming\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003e▷\u003c/span\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eLab D: Map-reduce in Erlang\u003c/p\u003e","frontPage":false},{"exportId":"gf8960f43af9a6505e59f7a3428062cd0","title":"Parallel Programming in Erlang","type":"WikiPage","content":"\u003cdiv class=\"event-detail-overflow\"\u003e\n\u003cp\u003eThis lecture introduces Erlang for Haskell programmers), taking parallelising quicksort as an example, both within one Erlang VM and distributed across a network. The latest version of the Erlang system can be downloaded from\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.erlang.org/downloads\" target=\"_blank\"\u003e\u003cspan\u003ehere\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e. There is a Windows installer. Many linux versions have an Erlang packagage available, but not necessarily a package suitable for development of Erlang code, and not necessarily the latest version. On Ubuntu, try\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003esudo apt-get install erlang-dev\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf that doesn't work or you can't find an appropriate package, build the VM from source.\u003c/p\u003e\n\u003cp\u003eSlides:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cspan\u003eThe \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"Parallel Programming in Erlang.pdf\" href=\"viewer/files/Parallel%20Programming%20in%20Erlang.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2702726\" data-api-returntype=\"File\"\u003eslides\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\n\u003cli\u003e\u003cspan\u003eA version of foo.erl can be found \u003ca class=\"instructure_file_link inline_disabled\" title=\"foo.erl\" href=\"viewer/files/foo.erl?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2702743\" data-api-returntype=\"File\"\u003ehere\u003c/a\u003e. (This file is provided as-is, in case you want to experiment with the code from the lecture--there are no comments, for example, and there is experimental code that didn't make it into the lecture).\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e","frontPage":false},{"exportId":"g552e221d2af7f07e64e7b20ee3821028","title":"Parallelising Haskell QuickCheck","type":"WikiPage","content":"\u003cdiv style=\"margin-top: 0; margin-bottom: 0;\"\u003eRobert Krook will talk about parallelization of the Haskell QuickCheck implementation.\u003c/div\u003e\n\u003cdiv style=\"margin-top: 0; margin-bottom: 0;\"\u003e\u003cspan style=\"font-size: 18pt;\"\u003eQuickerCheck!\u003c/span\u003e\u003c/div\u003e\n\u003cdiv style=\"margin-top: 0; margin-bottom: 0;\"\u003e\u003cstrong\u003eAbstract\u003c/strong\u003e:\u003c/div\u003e\n\u003cdiv style=\"margin-top: 0; margin-bottom: 0;\"\u003e\u003ca class=\"inline_disabled\" href=\"https://dl.acm.org/doi/abs/10.1145/351240.351266\" target=\"_blank\"\u003eQuickCheck\u003c/a\u003e is a wonderful tool for finding bugs in your program if you can define your specifications as properties. While QuickCheck is often presented to students using simple examples such as properties on lists or trees, QuickCheck can actually be used to test large, real world systems. Testing such systems can in many cases take a very long time, and you might be tempted to launch multiple instances of QuickCheck to test your properties. One downside with this approach, however, is that if each individual test takes a non-trivial amount of time to execute, shrinking also becomes slow business. Your computer will sound like a spaceship despite just one core being busy!\u003c/div\u003e\n\u003cdiv style=\"margin-top: 0; margin-bottom: 0;\"\u003eModifying the internal machinery of QuickCheck to make use of all the available cores can help speed up the testing process. In this lecture I will go over some very recent work I did on parallelizing the internal testing loop as well as the shrinking loop. In this course you are shown how you can achieve parallelism via the spark pool and the Par monad. To parallelize QuickCheck I use forkIO to spawn threads. I use asynchronous exceptions and MVars to communicate between them.\u003c/div\u003e\n\u003cdiv style=\"margin-top: 0; margin-bottom: 0;\"\u003eWhat initially appeared to be some simple engineering work turned out to challenge me in ways that I did not expect. I will show you some experimental results and things to think about when you run properties in parallel. Tests that may appear to be embarrassingly parallel might actually not be!\u003c/div\u003e\n\u003cp\u003eslides from the talk (animations got messed up, and appear as a single picture with everything overlayed) can be found here: \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"QuickerCheck.pdf\" href=\"viewer/files/Lectures/QuickerCheck.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003eQuickerCheck.pdf\u003c/a\u003e\u003c/p\u003e","frontPage":false},{"exportId":"ga9c92a3037048d56a321e80a020a8b88","title":"Robust Erlang","type":"WikiPage","content":"\u003cp\u003eThis lecture focusses on the fault tolerance constructs in Erlang--links and system processes--and the motivation for the \"Let It Crash\" philosophy. It introduces supervision trees and the Open Telecoms Platform, and develops a simple generic server.\u003c/p\u003e\n\u003cp\u003eSlides :\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe\u003cspan\u003e\u0026nbsp;\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"Robust Erlang.pdf\" href=\"viewer/files/Robust%20Erlang.pdf?canvas_download=1\u0026amp;canvas_qs_wrap=1\"\u003e\u003cspan class=\"instructure_file_holder link_holder\"\u003eslides\u003c/span\u003e\u003c/a\u003e\u003c/span\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","frontPage":false},{"exportId":"gc3d009d1eabc1b87631df86e26ee04ba","title":"Setup for Lab A","type":"WikiPage","content":"\u003cp\u003eTo get started with the lab (assuming you've installed the necessary tools):\u003c/p\u003e\n\u003cp\u003e1: Run\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003estack new LabA\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003ein your terminal.\u003c/p\u003e\n\u003cp\u003e2: Copy the lab handout (given.hs) into the\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003eapp/\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003edirectory.\u003c/p\u003e\n\u003cp\u003e3: Open package.yaml created by stack in the LabA directory and make the following changes:\u003c/p\u003e\n\u003cp\u003efrom\u003c/p\u003e\n\u003cpre\u003edependencies:\n- base \u0026gt;= 4.7 \u0026amp;\u0026amp; \u0026lt; 5\n\u003c/pre\u003e\n\u003cp\u003eto\u003c/p\u003e\n\u003cpre\u003edependencies:\n- base \u0026gt;= 4.7 \u0026amp;\u0026amp; \u0026lt; 5\n- random\n- criterion\n- parallel\n\u003c/pre\u003e\n\u003cp\u003eand from\u003c/p\u003e\n\u003cpre\u003eexecutables:\n  LabA-exe:\n    main:                Main.hs\n    source-dirs:         app\n    ghc-options:\n    - -threaded\n    - -rtsopts\n    - -with-rtsopts=-N\n    dependencies:\n    - LabA\n\u003c/pre\u003e\n\u003cp\u003eto\u003c/p\u003e\n\u003cpre\u003eexecutables:\n  LabA-exe:\n    main:                given.hs\n    source-dirs:         app\n    ghc-options:\n    - -threaded\n    - -rtsopts\n    - -eventlog\n    - -O2\n    - -feager-blackholing\n    dependencies:\n    - LabA\n\u003c/pre\u003e\n\u003cp\u003ePlease note that the\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003eeventlog\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eflag should only be used if you want to produce an event log for ThreadScope. To just get statistics with \u003ccode\u003e-s\u003c/code\u003e or to measure using Criterion, the eventlog flag should be removed, as gathering the event log messes up the measurements.\u003c/p\u003e\n\u003cp\u003eSimilarly, the\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003ethreaded\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eflag should only be used when you intend to use more than one thread. There will be times when you want to measure sequential behaviour, remembering that there are overheads associated with the threaded runtime.\u003c/p\u003e\n\u003cp\u003e4: Run\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ccode\u003estack build\u003c/code\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eto build the project.\u003c/p\u003e\n\u003cp\u003e5: Run the executable with e.g 4 thread while producing an event log for ThreadScope by running\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003estack run -- +RTS -lf -N4\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eYou can also get statistics using -s instead of -lf (but then you should not have used eventlog earlier). When you are done with all of these steps you are ready to begin working on the lab. Good luck!\u003c/p\u003e","frontPage":false},{"exportId":"g63e0192f3fd4b54d52423d4fca3e1d60","title":"Strategies","type":"WikiPage","content":"\u003cp\u003eThis lecture considers par and pseq more critically, and concludes that it might be a good idea to separate the control of behaviour relating to parallelisation from the description of the algorithm itself. The idea of Strategies is described in a well-known paper called\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003cspan class=\"instructure_file_holder link_holder\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"strategies93.pdf\" href=\"viewer/files/strategies93.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647965\" data-api-returntype=\"File\"\u003e\u003cspan\u003eAlgorithm + Strategy = Parallelism\u003c/span\u003e\u003c/a\u003e \u003c/span\u003eby Trinder, Hammond, Loidl and Peyton Jones. More recently, Marlow and some of the original authors have updated the idea, in\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003cspan class=\"instructure_file_holder link_holder\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"strategies10.pdf\" href=\"viewer/files/strategies10.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647966\" data-api-returntype=\"File\"\u003e\u003cspan\u003eSeq no more: Better Strategies for Parallel Haskel\u003c/span\u003e\u003cspan\u003el\u003c/span\u003e\u003c/a\u003e\u003c/span\u003e. Take a quick look at the first Strategies paper; it was very influential, and it is interesting to see how it led to the second one. The lecture is based on the newer paper and you should concentrate mostly on that paper. See also PCPH chapters 2 and 3.\u003c/p\u003e\n\u003cp\u003eSlides: \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"Lecture323.pdf\" href=\"viewer/files/Lecture323.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2692881\" data-api-returntype=\"File\"\u003eLecture323.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOther Material:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://hackage.haskell.org/package/parallel-3.2.2.0/docs/Control-Parallel-Strategies.html\" target=\"_blank\"\u003e\u003cspan\u003edocumentation of the Strategies Library\u0026nbsp;\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eis very helpful.\u003c/li\u003e\n\u003cli\u003eThe\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"http://www.cse.chalmers.se/~rjmh/Papers/whyfp.pdf\" target=\"_blank\"\u003e\u003cspan\u003elink to Why Functional Programming Matters\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","frontPage":false},{"exportId":"gb837439d011f26a8d68ffb77a3399b70","title":"the Par Monad","type":"WikiPage","content":"\u003cp\u003eThis lecture is about a programming model for deterministic parallelism, introduced by Simon Marlow and colleagues. It introduces the Par Monad, a monad for deterministic parallelism, and shows how I-structures are used to exchange information between parallel tasks (or \"blobs\"), see\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003ca class=\"external\" href=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2011/01/monad-par.pdf\" target=\"_blank\"\u003e\u003cspan\u003eMarlow's Haskell'11\u003c/span\u003e\u003cspan class=\"screenreader-only\"\u003e\u0026nbsp;(Links to an external site.)\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003epaper\u003cspan\u003e\u0026nbsp;\u003c/span\u003ewith Ryan Newton and Simon PJ. You should read this paper.\u003c/p\u003e\n\u003cp\u003eTake a look at the\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"IStructures.pdf\" href=\"viewer/files/IStructures.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647986\" data-api-returntype=\"File\"\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"IStructures.pdf\" href=\"viewer/files/IStructures.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647986\" data-api-returntype=\"File\"\u003eI-Structures paper\u003c/a\u003e \u003c/span\u003ereferred to in the lecture (not obligatory but interesting). See PCPH chapter 4.\u003c/p\u003e\n\u003cp\u003eAlso, Phil Wadler's\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003cspan class=\"instructure_file_holder link_holder\"\u003e\u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"monadsWadler.pdf\" href=\"https://chalmers.instructure.com/api/v1/canvadoc_session?blob=%7B%22moderated_grading_whitelist%22:null,%22enable_annotations%22:null,%22enrollment_type%22:null,%22anonymous_instructor_annotations%22:null,%22submission_id%22:null,%22user_id%22:125230000000000836,%22attachment_id%22:488172,%22type%22:%22canvadoc%22%7D\u0026amp;hmac=c7fee6010e899fa0a9b78d2b4d6114244823b7cd\"\u003e\"Essence of Functional Programming\"\u003c/a\u003e\u003c/span\u003e\u003cspan\u003e\u0026nbsp;\u003c/span\u003eis a very interesting read, and it covers monads and continuation passing style.\u003c/p\u003e\n\u003cp\u003eThe Par monad is based on Koen Claessen's Poor Man's Concurrency Monad (we call it PMC, see his\u003cspan\u003e\u0026nbsp;\u003c/span\u003e\u003cspan\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"PMCJFP.pdf\" href=\"viewer/files/PMCJFP.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647952\" data-api-returntype=\"File\"\u003eJFP Pearl\u003c/a\u003e).\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eBefore getting on to the Par monad, we take a look at Petricek's use of monad comprehensions and parallel list comprehensions combined with the Eval monad (see \u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"ParMonadPetricek.pdf\" href=\"viewer/files/ParMonadPetricek.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2698617\" data-api-returntype=\"File\"\u003ePetricek's paper\u003c/a\u003e, which I advise you to read). That paper can also help with understanding PMC.\u003c/p\u003e\n\u003cp\u003eSlides:\u003c/p\u003e\n\u003cp\u003e\u003ca class=\"inline_disabled\" href=\"https://docs.google.com/presentation/d/1y2g4D5Wb1Cu1VvH-k0RxeUhvbGpzB6avH20m3VO4AzI/edit?usp=drivesdk\" target=\"_blank\"\u003eKoen's slides about PMC (for info)\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"Lecture423.pdf\" href=\"viewer/files/Lecture423.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2698607\" data-api-returntype=\"File\"\u003eLecture423.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eUncommented Haskell code for playing with the Poor Man's Concurrency Monad \u003ca class=\"instructure_file_link instructure_scribd_file\" title=\"L3.hs\" href=\"viewer/files/L3.hs?canvas_download=1\u0026amp;canvas_qs_wrap=1\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647967\" data-api-returntype=\"File\"\u003eL3.hs\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eComment from Mary: The Par monad provides quite an attractive approach to deterministic parallel programming in Haskell. However, the question of what set of combinators should go on top of this to ease the job of the programmer has not been addressed as much as I expected when we started this course. The github version contains a \u003ca href=\"https://github.com/simonmar/monad-par/blob/master/monad-par-extras/Control/Monad/Par/Combinator.hs\"\u003efile of combinators\u003c/a\u003e but it is very much work in progress. If you find yourself with time on your hands, you might want to think about and implement some combinators. For instance, it would be nice to have combinators that express both how to break up input data and how to control task granularity. There is clearly more research to be done!\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eThe version of the Par monad that Max Algehed (a former student and then TA) has made that allows you to draw pictures of your programs is at\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca class=\"external\" href=\"https://github.com/MaximilianAlgehed/VisPar\" target=\"_blank\"\u003e\u003cspan\u003eVisPar\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","frontPage":false},{"exportId":"gf8b7084246e73011eb89da67b5e3bb74","title":"Threadscope demo","type":"WikiPage","content":"\u003cp\u003e\u003cspan style=\"text-decoration: underline;\"\u003eThreadscope Demo\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eIn this exercise session (on Friday 24/3 at 15:15) we are going to look more closely at Threadscope and how we can use it to analyse the parallel performance of our Haskell programs.\u003c/p\u003e\n\u003cp\u003eWe will look at associated topics, such as weak head normal form (WHNF), normal form (NF), thunks etc.\u003c/p\u003e","frontPage":false},{"exportId":"g2d0747ac3a74458c2b1143dc3e68bb76","title":"Virtual Machines for Functional Languages (Erik Stenman)","type":"WikiPage","content":"\u003cp\u003eErik talked about the design of both the BEAM (the virtual machine on which Erlang runs), and of FATE, a virtual machine for the smart contract language Sophia, which is itself implemented in Erlang. His slides can be found \u003ca class=\"inline_disabled\" href=\"https://prezi.com/view/ULD28xH67Z4e0bhS030e/\" target=\"_blank\"\u003ehere\u003c/a\u003e .\u003c/p\u003e","frontPage":false},{"exportId":"gb0dd4bccde2e2d314c91335895aaf4e8","title":"Yet another monad tutorial","type":"WikiPage","content":"\u003cp\u003eThis lecture is a beginner's introduction to monads, showing how we can use them to structure code that may fail, return multiple results, or perform I/O, with monadic parsing (and a brief introduction to monad transformers) as an example.\u003c/p\u003e\n\u003cp\u003eslides:\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"Yet Another Monad Tutorial.pdf\" href=\"viewer/files/Yet%20Another%20Monad%20Tutorial.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\"\u003e\u0026nbsp;Yet Another Monad Tutorial.pdf\u003c/a\u003e\u003c/p\u003e","frontPage":false}],"assignments":[{"exportId":"g10743106b5bd86eed4a5f19448a8094b","title":"Lab B","type":"Assignment","content":"\u003cp\u003eIn this lab assignment, you will speed up a simple Sudoku solver using parallelism.\u003c/p\u003e\n\u003cp\u003eThe assignment\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cspan\u003e\u003ca class=\"instructure_file_link instructure_scribd_file inline_disabled\" title=\"Sudoku Lab.pdf\" href=\"viewer/files/LabB_2022/Sudoku%20Lab.pdf?canvas_=1\u0026amp;canvas_qs_wrap=1\" target=\"_blank\" data-api-endpoint=\"https://chalmers.instructure.com/api/v1/courses/23443/files/2647994\" data-api-returntype=\"File\"\u003eSudoku Lab.pdf\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe sequential solver, for you to start from\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca class=\"external\" href=\"http://www.cse.chalmers.se/edu/year/2018/course/DAT280_Parallel_Functional_Programming/Material/Sudoku/sudoku.erl\" target=\"_blank\"\u003e\u003cspan\u003eerl\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eA set of benchmark problems\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca class=\"external\" href=\"http://www.cse.chalmers.se/edu/year/2018/course/DAT280_Parallel_Functional_Programming/Material/Sudoku/problems.txt\" target=\"_blank\"\u003e\u003cspan\u003etxt\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ca name=\"subm\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch3\u003eSubmission\u003c/h3\u003e\n\u003cp\u003eThis lab has two deadlines (see the deadlines in the Fire system):\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFirst deadline: You need to have made a serious effort on all obligatory parts of the lab assignment.\u003c/li\u003e\n\u003cli\u003eFinal deadline: You need to have passed the lab unless you have requested and been given an extension.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eYour submission needs to include the following information:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eYour parallelized code, as an Erlang module.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA file containing a brief description of the methods you used to parallelize your code, together with benchmark output and your analysis of it (see the lab description).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSubmit your lab report PDF and your source code into FIRE (NOT AS AN ARCHIVE).\u003c/p\u003e\n\u003cp\u003eBefore you submit your code, Clean It Up! Remember, submitting clean code is Really Important, and simply the polite thing to do. After you feel you are done, spend some time on cleaning your code; make it simpler, remove unnecessary things, etc. We will reject your solution if it is not clean.\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eWhen you are done, please submit using the Fire system.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eGood luck!\u003c/p\u003e","submissionTypes":null,"graded":false,"dueAt":null,"lockAt":null,"unlockAt":null}],"discussion_topics":[{"exportId":"g17a3ee2c827e3f27df408c0a31e8c50e","title":"Looking for lab partner","type":"DiscussionTopic","content":"Hi,\u003cbr\u003e\u003cbr\u003eI am looking for a lab partner.","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g9909f6773f068b5843bf144213ede312","title":"Lab partner","type":"DiscussionTopic","content":"\u003cp\u003eHello,\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u0026nbsp;\u003c/p\u003e\u003cp\u003ei'm looking for a lab partner.\u003c/p\u003e\u003cp\u003eplease reply to this or send me an email if you are interested!\u003c/p\u003e\u003cp\u003ealasiri@student.chalmers.se\u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false},{"exportId":"g5a1a42a2349a8211c0b800aa4c88ae2e","title":"Looking for lab partner ","type":"DiscussionTopic","content":"Hello! I am currently looking to partner up for the labs. If you are interested, reply to this post!\u0026nbsp;","lockAt":null,"unlockAt":null,"graded":false}],"quizzes":[],"files":[{"type":"folder","name":"Lectures","size":null,"files":[{"type":"file","name":"QuickerCheck.pdf","size":2075418,"files":null}]},{"type":"file","name":"Parallel Programming in Erlang.pdf","size":807477,"files":null},{"type":"file","name":"ErlangParallelSearch.pdf","size":358270,"files":null},{"type":"file","name":"futhark-lab-notes.pdf","size":197968,"files":null},{"type":"file","name":"ProgParallelAlgs.pdf","size":1436199,"files":null},{"type":"file","name":"lectureFuthark23.pdf","size":1111266,"files":null},{"type":"file","name":"foo.erl","size":6576,"files":null},{"type":"file","name":"PFPJava-exercise-sheet.pdf","size":111277,"files":null},{"type":"file","name":"IStructures.pdf","size":385512,"files":null},{"type":"file","name":"strategies10.pdf","size":427701,"files":null},{"type":"file","name":"chalmers-parfun-20230504.pdf","size":1118126,"files":null},{"type":"file","name":"HaskellSharedMemory.pdf","size":159234,"files":null},{"type":"file","name":"Yet Another Monad Tutorial.pdf","size":976052,"files":null},{"type":"file","name":"L3.hs","size":2267,"files":null},{"type":"file","name":"futhark-lab-notes.tar.gz","size":1393,"files":null},{"type":"file","name":"Composable Memory Transactions in Haskell.pdf","size":3588605,"files":null},{"type":"file","name":"Databases for the New World.pdf","size":739451,"files":null},{"type":"file","name":"Lecture323.pdf","size":2659176,"files":null},{"type":"file","name":"PMCJFP.pdf","size":196433,"files":null},{"type":"folder","name":"LabB_2022","size":null,"files":[{"type":"file","name":"Sudoku Lab.pdf","size":84134,"files":null}]},{"type":"file","name":"Concurrency 2023.pdf","size":3837840,"files":null},{"type":"folder","name":"Exercise","size":null,"files":[]},{"type":"file","name":"Parallel Functional Programming.pdf","size":2840073,"files":null},{"type":"file","name":"strategies93.pdf","size":292047,"files":null},{"type":"folder","name":"unfiled","size":null,"files":[]},{"type":"file","name":"ising-handout.tar.gz","size":3690,"files":null},{"type":"file","name":"crawl.erl","size":2940,"files":null},{"type":"file","name":"map_reduce.erl","size":2482,"files":null},{"type":"file","name":"ParMonadPetricek.pdf","size":282076,"files":null},{"type":"file","name":"page_rank.erl","size":954,"files":null},{"type":"file","name":"Lecture423.pdf","size":2407611,"files":null},{"type":"file","name":"FutharkLab23.pdf","size":146823,"files":null},{"type":"folder","name":"Demos","size":null,"files":[{"type":"file","name":"sat_parallel.pdf","size":139169,"files":null},{"type":"file","name":"formula.txt","size":4839,"files":null},{"type":"file","name":"sat_2022_04_08.erl","size":6472,"files":null},{"type":"file","name":"harder.txt","size":6767,"files":null}]},{"type":"file","name":"LectureDP123.pdf","size":1711944,"files":null},{"type":"file","name":"Robust Erlang.pdf","size":860689,"files":null},{"type":"file","name":"Chalmers lecture.pdf","size":12501642,"files":null}]}