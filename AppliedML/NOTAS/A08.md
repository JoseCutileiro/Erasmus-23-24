# Aula 8: Tuning Hyperparameters

Video: https://www.youtube.com/watch?v=XXC9Yw0RRqI

## O que são hyperparametros? 

São inputs que damos aos nossos algoritmos de ML, estes inputs controlam de alguma forma o comportamento base dos nossos algoritmos bem como a sua complexidade e adequação aos dados, muitas vezes são estes parametros que fazem com que o algoritmo funcione ou não 

Exemplos:

1. Decision trees: Depth
2. Random forests: Ensemble size
3. ...

## Nota para o projeto

Hyperparametros interessantes das random forests: depth, ensemble size, criterion (majority sum, info gain, gini)

À medida que os algoritmos ficam mais complexos normalmente existem mais hyperparametros.

Exemplo do professor: LinearSVC (support vector classifier), este modelo tem 10 hyperparametros que podemos modificar (é muito)

## Como obter bons resultados? 

1. Não fazer nada 
2. Tentar utilizar conhecimento de dominio
3. Tentativa e erro (pode ser impossivel...)

GRID SEARCH => Todas as combinações são utilizadas a melhor é selecionada. (no scikit-learn: GridSearchCV)

RANDOM SEARCH => Funciona bem quando não tens assim tantos hyperparameters. Este aproach é muito bom se não tiveres assim tantos recursos para gastar, fazes uma data de randoms e escolhes o melhor naquele timeframe. É preciso perceber a distribuição dos hyperparametros para escolher os valores aleatorios de maneira correta. (no scikit-learn: RandomizedSearchCV)

Estas soluções são brute force, não encontramos nada que pareça mais inteligente? (bayesian optimization, stochastic optimization) isto é chamado black-box optimization dado que não sabemos muito bem como é que o podemos fazer.

Nota: AutoML (fazer este processo todo mas sozinho)
