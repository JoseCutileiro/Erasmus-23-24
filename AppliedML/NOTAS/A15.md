# Aula 15: Optimizing objective functions

Video: https://www.youtube.com/watch?v=J5QF92e7OBY

## Objective functions

Minimizar (ou maximizar) uma função objetivo, normalmente com uma loss function e um regularizador

1. loss function: para percebermos os resultados efetivamente que o nosso modelo têm
2. regularizador: para medirmos a complexidade do nosso modelo e perceber se vale a pena manter ou elevar a complexidade dados um certo resultado

Exemplo: minimizar os squared errors 

f = (1/N) * sum(w * x - y)^2 

Como minimizar ---> GRADIENT

Intuitivamente o gradiente "aponta" parao sitio que queremos (isto se formos exatamente no sentido oposto claro). A ideia é calcular o gradiente em cada ponto e ir descendo

Gradient descent
```
w = init_w()
lr = init_learning_rate()

while (not close to optimum):
    compute gradient
    if gradient is small than threshol we are done
    else subtract lr * gradient
    repetir
```

Problemas: O learning rate tem que ser bem definido caso contrario podemos entrar em loop. Também podemos ter um learning rate que se adapta automaticamente, normalmente esta solução é poderosa. Solução simples: começar com um lr alto e ir reduzing para não ter problemas. Existem outras soluções que tentam resolver este problema olhando diretamente para o valor do gradiente calculado. Outro problema comum é a existência de minimos/maximos locais. Em que o gradiente acaba por ficar estagnado ... Uma solução é usar o beam search, é inicializar os w em multiplos pontos ao calhas.

Funções convexas: Se a função for convexa e encontrarmos um minimo então este minimo é certamente local. Exemplo: Squared error é convexo. Mas isto não é o caso em todos os algoritmos de ML. 

Variante do gradiente descent: STOCASTIC GRADIENT DESCENT. SGD é miuto eficiente nos dias de hoje graças às GPUs que permitem o processamento de código em paralelo muito rapidamente. SGD usa por definição um e apenas um elemento do training set de cada vez, mas podemos criar variantes desta versão (os chamados minibatch) que utilizam multiplas entragas do training set em paralelo.

SGD pseudo
```
iniciar o w e o lr 

while 
    escolher um x
    calcular o gradiente apenas com este x
    está ok -> acaba
    não está ok -> atualiza o w (w = w - lr * grad)
    repetir
```

Quando terminar o SGD? 

solução simples: Escolher um número de iterações
solução mais complexa: early stopping

mais sobre early stopping: "In machine learning, early stopping is a form of regularization used to avoid overfitting when training a learner with an iterative method, such as gradient descent. Such methods update the learner so as to make it better fit the training data with each iteration."@wikipedia