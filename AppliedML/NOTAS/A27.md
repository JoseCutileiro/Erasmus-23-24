# Aula 27: Introduction to Convolutional Neural

Video: https://www.youtube.com/watch?v=m1cJyowhG_s

## Motivação

Hoje em dia são as soluções padrões para lidar com problemas de classificação de imagens 

Como representar uma imagem? 

Uma imagem é um conjunto de pixeis, cada pixel representa uma cor. Existem muitas paletes de cores disponiveis, as mais comuns sao o RGB ou o black and white. 

Existem muitos formatos

1. Direct formats: BMP ou TIFF: Guardam tudo, o que pode ser muito eficiente.
2. Compressed lossless formats: PNG: Guardam tudo de forma eficiente
3. Compressed lossy format: JPEG: Guargam tudo com um pouco de perda de informação

Existem ainda alguns formatos especificos para cada dominio (exemplo: imagens médicas)

## Como contruir um Modelo que seja capaz dee lidar com imagens?

Modelos lineares: Não conseguem captar as interações entre as features ... O que aqui é completamente importante

Decision trees (and random forests): Podem apanhar estas relações, mas de modo muito ineficaz, teriam de ter um tamanho muitérrimo grande dada a grande explosão combinatória deste problema. 

## Soluções de antigamente: 

Fazer feature extraction em esteróides para imagens. Tentamos encontrar padrões que aparecem nas imagens e depois ficamos com estes padrões para nós. Exemplo: SIFT. Por exemplo para texto temos o BAG OF WORDS. 

Contudo isto não é escalável e dá muito trabalho.

Então e as NN? Elas conseguem aprender as abstrações autaticamente, isto não funciona? 

Sim funciona, mas o número de parametros também não é escalavel. Exemplo: Para lidar com uma imagem de 200x200 com 40 hidden units fica com aproximadamente 2 biliões de parametros ... E ainda há um problema gigante. Não consegue lidar com SHIFTS. E lidar com shifts em imagens parece algo que é importante de resolver.

## CNNs

Ideia: Apanhar padrões, também terá uma 'stacked architecture' e também será capaz de lidar com funções não lineares.

## Na próxma aula:

Building blocks: filters, kernels, pooling
Truques: Data augmentation, transfer learning, interpretation