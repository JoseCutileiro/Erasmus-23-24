# Aula 14: Calculus refresher

Video: https://www.youtube.com/watch?v=Wz6wlkqkd4w

## Objective function

Em muitos ML algorithms treinamos um modelos atraves da otimização de funcoes objetivos. Escolhemos parametros que nos e atraves da escolha destes parametros vemos os resultados. Para perceber isto precisamos de perceber matemática (exemplo: gradientes e cenas ...)

Os nossos dados ===> O nosso modelo y = w * x

Como escolher o melhor w? 

## Naive:

Escolhemos vários valores do w e vemos qual é um que seria bom e ficamos por aqui. Claro que isto é insuficiente e não obterá resultados muito bons

## MSE

Mean square error: (1/n) * sum(y - w * x)^2

Para cada valor diferente de w iremos obter um resultado da MSE que serve para avaliar a qualidade do nosso w. 

Minimizar o MSE

## Otimization task 

unconstrained optimization: Encontrar o w que nos dá o minimo (ou máximo) de uma dada função f

MSE: para uma unica variavel, mas como é de esperar em ML temos que generalizar isto para um número arbitrario de dimensões. Aqui é que entra o gradiente. O gradiente é zero então temos um optimum (valor otimo)

Nice function: Se tiver um máximo ou um minimo então a sua derivada é zero.

Como fazer os gradientes? 

1. Saber calculo
2. Na pratica nao fazemos isto à mão -> Pytorch e tensorFlow ou Maple, Mathematica.

