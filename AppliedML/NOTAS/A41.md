# Aula 41: Introduction to Transformers

Video: https://www.youtube.com/watch?v=3P_YqkIAOVQ

## Transformers: Uma familia de arquiteturas

Palavras chave:

1. Mecanismo de atenção 
2. Encoders => Sumarizar o input
3. Decoders => Gerar o output

Podemos ter só o decoder => Language model

Podemor ter só o encoder => Representar o modelo

Depois podemos encaixar este blocos em modelos diferentes

Existem ainda mais truques (camadas intermédias): Layer normalization, residual connection => importantes para se quisermos ter um modelo muito profundo.

## Nota:

Infelizemente o professor não fala muito disto portanto vou deixar isto para depois