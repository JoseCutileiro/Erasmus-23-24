# Aula 29: CNN Tricks

Video: https://www.youtube.com/watch?v=EGqqbSE94L0

## Aula de hoje:

1. Modelos pre-treinados e transfer learning
2. data augmentation
3. interpreting Cnns

## Pre-trained models

Transfer learning: Queremos aproveitar o que já fizemos num dado modelo anteriormente e transferir o conhecimento para um nobo modelo. Normalmente isto é feito com a reutuilização dos pesos encontrados por um dado modelo. Não só torna o processo de construir novos modelos mais rápido, como permite construir modelos em dominios que têm poucos dados.

Transfer learning in vision: ImageNet é um dataset com todo o tipo de imagens, é muito genérico, carros, casas, comida, ... Com este dataset podemos criar um sistema muito genérico e pouco especializado. Mas depois podemos aproveitar este modelo e alimentá-lo com um dataset mais especifico. 

Como o modelo está pre-treinado nem nos precisamos de preocupar em treina-lo de novo.

## Duas formas de usar modelos pre treinados:

1. Utilizar um modelo pre-treinado com pesos congelados. (não deixamos atualizar os novos pesos)
2. Utilizar um modelo pre-treinado mas permitimos que os pesos sejam atualizados.

## Overfitting nas Cnns

Cnns são modelos muito complexos e profundos, por isso têm uma grande facilidade de entrar em regime de overfitting. 

Para evitar overfitting basta -> regularization, early stopping and dropout

Mas existe outra maneira -> data augmentation (aplicar random noising, shearing, rotating, darkening, flipping...). Isto também é uma forma de parametrização. (o quanto de augmentation é que podemos aplicar)

## Intrepertar as Cnns (desenhar os filtros)

- Feature visualization
- Perceber as decisões do modelo. Exemplo: Porque é que a rede acha que 